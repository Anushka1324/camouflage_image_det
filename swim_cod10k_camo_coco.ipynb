{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "694f1c87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T08:38:30.038665Z",
     "iopub.status.busy": "2026-01-10T08:38:30.038400Z",
     "iopub.status.idle": "2026-01-10T08:38:32.512915Z",
     "shell.execute_reply": "2026-01-10T08:38:32.512247Z"
    },
    "papermill": {
     "duration": 2.484393,
     "end_time": "2026-01-10T08:38:32.514259",
     "exception": false,
     "start_time": "2026-01-10T08:38:30.029866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, random, math, time\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9adf2a33",
   "metadata": {
    "_cell_guid": "53c610f7-732b-435e-9459-de2f9e3d80c7",
    "_uuid": "d0b94887-4b0f-4317-84c8-1a7777d760d0",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-10T08:38:32.528168Z",
     "iopub.status.busy": "2026-01-10T08:38:32.527871Z",
     "iopub.status.idle": "2026-01-10T08:38:50.928450Z",
     "shell.execute_reply": "2026-01-10T08:38:50.927869Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 18.408843,
     "end_time": "2026-01-10T08:38:50.929898",
     "exception": false,
     "start_time": "2026-01-10T08:38:32.521055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torchvision import transforms, models\n",
    "from torchvision.transforms import RandAugment\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3f0cde9",
   "metadata": {
    "_cell_guid": "63fe8b36-a02c-4487-a769-3e87f2989073",
    "_uuid": "23ff4136-a399-4879-b737-c64e8a7b9c6d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-10T08:38:50.944149Z",
     "iopub.status.busy": "2026-01-10T08:38:50.943591Z",
     "iopub.status.idle": "2026-01-10T08:38:54.088983Z",
     "shell.execute_reply": "2026-01-10T08:38:54.088189Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 3.153528,
     "end_time": "2026-01-10T08:38:54.090350",
     "exception": false,
     "start_time": "2026-01-10T08:38:50.936822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "from collections import Counter\n",
    "from sklearn.manifold import TSNE\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "import graphviz\n",
    "from graphviz import Digraph\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1dcb79d",
   "metadata": {
    "_cell_guid": "8c96bf9f-8a4a-4b5b-ba3c-cc2904b1ab58",
    "_uuid": "2072ad41-1769-40e0-9dc2-ff2324551b11",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-10T08:38:54.104952Z",
     "iopub.status.busy": "2026-01-10T08:38:54.104585Z",
     "iopub.status.idle": "2026-01-10T08:38:54.202432Z",
     "shell.execute_reply": "2026-01-10T08:38:54.201616Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.105961,
     "end_time": "2026-01-10T08:38:54.203643",
     "exception": false,
     "start_time": "2026-01-10T08:38:54.097682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if device == \"cuda\": torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66f1258c",
   "metadata": {
    "_cell_guid": "1ca1b022-43ef-4a4f-9bc8-9502667f799e",
    "_uuid": "b9c000da-bf1a-4523-bbb1-7b28ff015f10",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-10T08:38:54.217024Z",
     "iopub.status.busy": "2026-01-10T08:38:54.216807Z",
     "iopub.status.idle": "2026-01-10T08:38:54.221185Z",
     "shell.execute_reply": "2026-01-10T08:38:54.220527Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.01229,
     "end_time": "2026-01-10T08:38:54.222326",
     "exception": false,
     "start_time": "2026-01-10T08:38:54.210036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 8         # adjust if OOM\n",
    "EPOCHS = 15\n",
    "NUM_WORKERS = 4         # set 0 if worker issues on Kaggle\n",
    "LR = 3e-4\n",
    "LABEL_SMOOTH = 0.1\n",
    "SAVE_PATH = \"best_model.pth\"\n",
    "USE_SEGMENTATION = True\n",
    "\n",
    "# Loss weights from PDF suggestion\n",
    "ALPHA_DOM = 0.5\n",
    "BETA_SUPCON = 0.3\n",
    "ETA_CONS = 0.1\n",
    "GAMMA_SEG = 0.5\n",
    "\n",
    "# Mixup/CutMix probabilities and alphas\n",
    "PROB_MIXUP = 0.5\n",
    "PROB_CUTMIX = 0.5\n",
    "MIXUP_ALPHA = 0.2\n",
    "CUTMIX_ALPHA = 1.0\n",
    "\n",
    "# warmup epochs\n",
    "WARMUP_EPOCHS = 5\n",
    "\n",
    "# early stopping\n",
    "EARLY_STOPPING_PATIENCE = 7\n",
    "FREEZE_EPOCHS = 5\n",
    "ACCUMULATION_STEPS = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9cbe7d",
   "metadata": {
    "_cell_guid": "6b93dda5-4bd4-4cc5-897f-2e3f7ce8d878",
    "_uuid": "32b3ea07-c3c9-4592-81c8-7e7c5f53b060",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.005884,
     "end_time": "2026-01-10T08:38:54.234427",
     "exception": false,
     "start_time": "2026-01-10T08:38:54.228543",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Noise + Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "511f3c29",
   "metadata": {
    "_cell_guid": "a36a568a-587b-4e7d-95ea-3a45d5fa1652",
    "_uuid": "8610d19e-aa2c-4c65-8dd3-63efff268002",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-10T08:38:54.247593Z",
     "iopub.status.busy": "2026-01-10T08:38:54.246975Z",
     "iopub.status.idle": "2026-01-10T08:38:54.254072Z",
     "shell.execute_reply": "2026-01-10T08:38:54.253550Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.014617,
     "end_time": "2026-01-10T08:38:54.255008",
     "exception": false,
     "start_time": "2026-01-10T08:38:54.240391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=0.05):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "    def __call__(self, tensor):\n",
    "        noise = torch.randn(tensor.size()) * self.std + self.mean\n",
    "        noisy_tensor = tensor + noise\n",
    "        return torch.clamp(noisy_tensor, 0., 1.)\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + f'(mean={self.mean}, std={self.std})'\n",
    "\n",
    "weak_tf = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    AddGaussianNoise(0., 0.02),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n",
    "strong_tf = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ColorJitter(0.4,0.4,0.4,0.1),\n",
    "    RandAugment(num_ops=2, magnitude=9),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ToTensor(),\n",
    "    AddGaussianNoise(0., 0.05),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "val_tf = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59846f47",
   "metadata": {
    "_cell_guid": "0439529c-c10a-4627-b237-6d1ea7c53173",
    "_uuid": "8a0980ba-9609-4279-9de2-cd19d8a166b9",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-10T08:38:54.268148Z",
     "iopub.status.busy": "2026-01-10T08:38:54.267942Z",
     "iopub.status.idle": "2026-01-10T08:38:54.286521Z",
     "shell.execute_reply": "2026-01-10T08:38:54.285983Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.026492,
     "end_time": "2026-01-10T08:38:54.287552",
     "exception": false,
     "start_time": "2026-01-10T08:38:54.261060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# weak_tf = transforms.Compose([transforms.Resize((IMG_SIZE, IMG_SIZE)), transforms.ToTensor()])\n",
    "# strong_tf = transforms.Compose([transforms.Resize((IMG_SIZE, IMG_SIZE)), transforms.ToTensor()])\n",
    "# val_tf = transforms.Compose([transforms.Resize((IMG_SIZE, IMG_SIZE)), transforms.ToTensor()])\n",
    "\n",
    "# reading a file with multiple encodings\n",
    "def read_file_with_encoding(file_path, encodings=['utf-8', 'utf-8-sig', 'ISO-8859-1']):\n",
    "    \"\"\"Tries to read a file using a list of common encodings.\"\"\"\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding=encoding) as f:\n",
    "                return f.readlines()\n",
    "        except UnicodeDecodeError:\n",
    "            print(f\"Failed to read {file_path} with encoding {encoding}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file_path}: {e}\")\n",
    "    raise RuntimeError(f\"Unable to read {file_path} with any of the provided encodings.\")\n",
    "\n",
    "def load_testing_dataset_info(info_file, image_dir):\n",
    "    \"\"\"Loads image paths and labels from the testing dataset info file.\"\"\"\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    \n",
    "    # List of encodings to try\n",
    "    encodings = ['utf-8-sig', 'utf-8', 'ISO-8859-1', 'latin-1']\n",
    "    lines = []\n",
    "    \n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            with open(info_file, 'r', encoding=encoding) as f:\n",
    "                lines = f.readlines()\n",
    "            break  # If successful, break out of the loop\n",
    "        except UnicodeDecodeError:\n",
    "            print(f\"Failed to read {info_file} with encoding {encoding}. Trying another encoding...\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {info_file}: {e}\")\n",
    "            raise \n",
    "\n",
    "    for line in lines:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) == 2:\n",
    "            image_filename = parts[0]\n",
    "            # Ensure label is always 0 or 1\n",
    "            try:\n",
    "                label = int(parts[1])\n",
    "            except ValueError:\n",
    "                continue # Skip malformed lines\n",
    "                \n",
    "            label = 1 if label == 1 else 0  # Map label '1' to CAM and '0' to Non-CAM\n",
    "            image_full_path = os.path.join(image_dir, image_filename)  # Combine with image directory\n",
    "            image_paths.append(image_full_path)\n",
    "            labels.append(label)\n",
    "    \n",
    "    return image_paths, labels\n",
    "\n",
    "\n",
    "# MultiDataset class with proper encoding handling\n",
    "class MultiDataset(Dataset):\n",
    "    def __init__(self, root_dirs, txt_files, testing_image_paths=None, testing_labels=None, weak_transform=None, strong_transform=None, use_masks=True):\n",
    "        self.root_dirs = root_dirs\n",
    "        self.weak_transform = weak_transform\n",
    "        self.strong_transform = strong_transform\n",
    "        self.use_masks = use_masks\n",
    "        self.samples = []\n",
    "\n",
    "        # Handle the testing dataset (testing-dataset images and labels)\n",
    "        if testing_image_paths is not None and testing_labels is not None:\n",
    "            for img_path, label in zip(testing_image_paths, testing_labels):\n",
    "                # Samples from testing-dataset are stored as 2-element tuples (img_path, label)\n",
    "                self.samples.append((img_path, label)) \n",
    "        \n",
    "        # Process other datasets (COD10K, CAMO, etc.)\n",
    "        if isinstance(txt_files, str):\n",
    "            txt_files = [txt_files]\n",
    "\n",
    "        all_lines = []\n",
    "        for t in txt_files:\n",
    "            if not os.path.exists(t):\n",
    "                raise RuntimeError(f\"TXT file not found: {t}\")\n",
    "\n",
    "            # Use the read_file_with_encoding function to handle different encodings\n",
    "            lines = read_file_with_encoding(t)\n",
    "            all_lines.extend([(line.strip(), t) for line in lines if line.strip()])\n",
    "\n",
    "        for line, src_txt in all_lines:\n",
    "            parts = line.split()\n",
    "            if len(parts) == 0:\n",
    "                continue\n",
    "\n",
    "            fname = parts[0]\n",
    "            if len(parts) >= 2:\n",
    "                try:\n",
    "                    lbl = int(parts[1])\n",
    "                except:\n",
    "                    # Fallback classification if label is not an integer\n",
    "                    lbl = 1 if \"CAM\" in fname or \"cam\" in fname else 0\n",
    "            else:\n",
    "                lbl = 1 if \"CAM\" in fname or \"cam\" in fname else 0\n",
    "            \n",
    "            # Map labels to binary (CAM=1, Non-CAM=0)\n",
    "            lbl = 1 if lbl == 1 else 0\n",
    "\n",
    "            found = False\n",
    "            search_subs = [\n",
    "                \"\",  # If image is directly in root_dir (less common)\n",
    "                \"Image\", \"Imgs\", \"images\", \"JPEGImages\", \"img\", # Common image folders \n",
    "                \"Images/Train\", \"Images/Test\", # CAMO-COCO style paths\n",
    "            ]\n",
    "            \n",
    "            base_fname = os.path.basename(fname)  \n",
    "\n",
    "            for rdir in self.root_dirs:\n",
    "                for sub in search_subs:\n",
    "                    img_path = os.path.join(rdir, sub, base_fname)\n",
    "                    if os.path.exists(img_path):\n",
    "                        # Samples from COD/CAMO are stored as 3-element tuples (img_path, lbl, rdir)\n",
    "                        self.samples.append((img_path, lbl, rdir))\n",
    "                        found = True\n",
    "                        break\n",
    "                if found:\n",
    "                    break\n",
    "\n",
    "            if not found:\n",
    "                print(f\"[WARN] File not found in any root: {base_fname} (Searched in {self.root_dirs})\")\n",
    "\n",
    "        if len(self.samples) == 0:\n",
    "            raise RuntimeError(f\"No valid samples found from {txt_files}\")\n",
    "\n",
    "        print(f\"✅ Loaded {len(self.samples)} samples from {len(self.root_dirs)} root directories.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        global IMG_SIZE \n",
    "        \n",
    "        sample = self.samples[idx]\n",
    "        \n",
    "        img_path = sample[0]\n",
    "        lbl = sample[1]\n",
    "        \n",
    "        # Define rdir for consistent mask lookup logic\n",
    "        if len(sample) == 3:\n",
    "            # If it's a 3-element tuple (COD/CAMO), rdir is the third element\n",
    "            rdir = sample[2]\n",
    "            # Root directory for testing-dataset (used as fallback for mask lookup)\n",
    "            testing_root = None \n",
    "        else:\n",
    "            rdir = os.path.dirname(os.path.dirname(img_path))\n",
    "            # Set testing_root explicitly for clarity if needed later, but rdir is now defined.\n",
    "\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.weak_transform:\n",
    "            weak = self.weak_transform(img)\n",
    "        else:\n",
    "            weak = transforms.ToTensor()(img)\n",
    "            \n",
    "        if self.strong_transform:\n",
    "            strong = self.strong_transform(img)\n",
    "        else:\n",
    "            strong = weak.clone()\n",
    "\n",
    "        mask = None\n",
    "        if self.use_masks:\n",
    "            mask_name = os.path.splitext(os.path.basename(img_path))[0] + \".png\"\n",
    "            \n",
    "            # Use the defined rdir for mask search\n",
    "            found_mask = False\n",
    "            for mask_dir in [\"GT_Object\", \"GT\", \"masks\", \"Mask\"]:\n",
    "                mask_path = os.path.join(rdir, mask_dir, mask_name)\n",
    "                \n",
    "                if os.path.exists(mask_path):\n",
    "                    m = Image.open(mask_path).convert(\"L\").resize((IMG_SIZE, IMG_SIZE))\n",
    "                    m = np.array(m).astype(np.float32) / 255.0\n",
    "                    # Convert to binary mask: 0 or 1\n",
    "                    mask = torch.from_numpy((m > 0.5).astype(np.float32)).unsqueeze(0)\n",
    "                    found_mask = True\n",
    "                    break\n",
    "\n",
    "            if mask is None:\n",
    "                mask = torch.zeros((1, IMG_SIZE, IMG_SIZE), dtype=torch.float32)\n",
    "                \n",
    "        return weak, strong, lbl, mask\n",
    "\n",
    "def build_weighted_sampler(dataset):\n",
    "    \"\"\"\n",
    "    Builds a WeightedRandomSampler based on class imbalance.\n",
    "    FIXED: Safely extracts label (index 1) from both 2-element and 3-element tuples.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Safely extract labels (always index 1, regardless of tuple length)\n",
    "    labels = [sample[1] for sample in dataset.samples]  \n",
    "    \n",
    "    counts = Counter(labels)\n",
    "    total = len(labels)\n",
    "    \n",
    "    # Ensure there are at least two classes to calculate class_weights\n",
    "    if len(counts) <= 1:\n",
    "        print(f\"[WARN] Only {len(counts)} class(es) found. Using equal weights.\")\n",
    "        weights = [1.0] * total\n",
    "    else:\n",
    "        # Calculate inverse frequency weights\n",
    "        class_weights = {c: total / (counts[c] * len(counts)) for c in counts}\n",
    "        weights = [class_weights[lbl] for lbl in labels]\n",
    "        \n",
    "    return WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d197e9",
   "metadata": {
    "_cell_guid": "b86311ae-c1bb-4f22-91c0-d3d43ff59d08",
    "_uuid": "0e0569d2-4f3f-47be-ba5a-80aac8370acb",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.005786,
     "end_time": "2026-01-10T08:38:54.299504",
     "exception": false,
     "start_time": "2026-01-10T08:38:54.293718",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "724675b4",
   "metadata": {
    "_cell_guid": "8612016c-9564-42f6-be27-48e77e56c6eb",
    "_uuid": "2977418b-5a9b-4b00-bd2b-6e6d1380c03a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-10T08:38:54.313589Z",
     "iopub.status.busy": "2026-01-10T08:38:54.313388Z",
     "iopub.status.idle": "2026-01-10T08:39:27.000196Z",
     "shell.execute_reply": "2026-01-10T08:39:26.999446Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 32.701698,
     "end_time": "2026-01-10T08:39:27.007040",
     "exception": false,
     "start_time": "2026-01-10T08:38:54.305342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 8605 samples from 4 root directories.\n",
      "✅ Loaded 2152 samples from 4 root directories.\n",
      "Total Train samples: 8605 Total Val samples: 2152\n"
     ]
    }
   ],
   "source": [
    "info_dir = \"/kaggle/input/cod10k/COD10K-v3/Info\"\n",
    "train_dir_cod = \"/kaggle/input/cod10k/COD10K-v3/Train\" \n",
    "test_dir_cod = \"/kaggle/input/cod10k/COD10K-v3/Test\"  \n",
    "    \n",
    "# COD10K Info files\n",
    "train_cam_txt = os.path.join(info_dir, \"CAM_train.txt\")\n",
    "train_noncam_txt = os.path.join(info_dir, \"NonCAM_train.txt\")\n",
    "test_cam_txt = os.path.join(info_dir, \"CAM_test.txt\")\n",
    "test_noncam_txt = os.path.join(info_dir, \"NonCAM_test.txt\")\n",
    "\n",
    "# CAMO-COCO PATHS\n",
    "info_dir2 = \"/kaggle/input/camo-coco/CAMO_COCO/Info\"\n",
    "\n",
    "# CAMO-COCO Info files\n",
    "train_cam_txt2 = os.path.join(info_dir2, \"camo_train.txt\")\n",
    "train_noncam_txt2 = os.path.join(info_dir2, \"non_camo_train.txt\")\n",
    "test_cam_txt2 = os.path.join(info_dir2, \"camo_test.txt\")\n",
    "test_noncam_txt2 = os.path.join(info_dir2, \"non_camo_test.txt\")\n",
    "\n",
    "# CAMO-COCO Root Directories\n",
    "train_dir_camo_cam = \"/kaggle/input/camo-coco/CAMO_COCO/Camouflage\"\n",
    "train_dir_camo_noncam = \"/kaggle/input/camo-coco/CAMO_COCO/Non_Camouflage\"\n",
    "\n",
    "# third dataset - NC4K + non-camouflage (places 365)\n",
    "testing_info_file = \"/kaggle/input/testing-dataset/Info/image_labels.txt\"\n",
    "testing_images_dir = \"/kaggle/input/testing-dataset/Images\"\n",
    "testing_image_paths, testing_labels = load_testing_dataset_info(testing_info_file, testing_images_dir)\n",
    "# 1. Load the testing dataset info\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "    testing_image_paths, testing_labels, test_size=0.2, random_state=42\n",
    ")\n",
    "# 1. All Root Directories\n",
    "ALL_ROOT_DIRS = [\n",
    "    train_dir_cod,       \n",
    "    test_dir_cod,       \n",
    "    train_dir_camo_cam,  \n",
    "    train_dir_camo_noncam\n",
    "]\n",
    "# 2. Training TXT files: ALL COD10K/CAMO-COCO data (both train and test splits)\n",
    "ALL_TRAIN_TXTS = [\n",
    "    train_cam_txt2, train_noncam_txt2, \n",
    "]\n",
    "# 3. Validation TXT files: ONLY the 80% testing-dataset split will be used, so this list is empty.\n",
    "ALL_VAL_TXTS = [test_cam_txt2, test_noncam_txt2]\n",
    "train_ds = MultiDataset(\n",
    "    root_dirs=ALL_ROOT_DIRS, \n",
    "    txt_files=ALL_TRAIN_TXTS,               \n",
    "    testing_image_paths=train_paths,        \n",
    "    testing_labels=train_labels,            \n",
    "    weak_transform=weak_tf, \n",
    "    strong_transform=strong_tf, \n",
    "    use_masks=USE_SEGMENTATION\n",
    ")   # Validation Dataset: No external data (via empty ALL_VAL_TXTS) + 80% testing-dataset split (via val_paths)\n",
    "val_ds = MultiDataset(\n",
    "    root_dirs=ALL_ROOT_DIRS,  \n",
    "    txt_files=ALL_VAL_TXTS,                 \n",
    "    testing_image_paths=val_paths,              \n",
    "    testing_labels=val_labels,              \n",
    "    weak_transform=val_tf, \n",
    "    strong_transform=None, \n",
    "    use_masks=USE_SEGMENTATION\n",
    ")\n",
    "\n",
    "# Build Sampler and DataLoader\n",
    "train_sampler = build_weighted_sampler(train_ds)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, sampler=train_sampler, num_workers=NUM_WORKERS)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "print(\"Total Train samples:\", len(train_ds), \"Total Val samples:\", len(val_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3e3365",
   "metadata": {
    "_cell_guid": "27410294-010a-4911-a7fe-8047a41f96b7",
    "_uuid": "9147384c-1b50-4cf1-93a9-da0d89a0615f",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.005966,
     "end_time": "2026-01-10T08:39:27.019219",
     "exception": false,
     "start_time": "2026-01-10T08:39:27.013253",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Backbones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b39a924",
   "metadata": {
    "_cell_guid": "7c590a73-9329-416b-b0e9-3cc63b6c61f7",
    "_uuid": "0562f881-a9a2-425b-84f7-b87f9f1de827",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-10T08:39:27.032329Z",
     "iopub.status.busy": "2026-01-10T08:39:27.032101Z",
     "iopub.status.idle": "2026-01-10T08:39:27.037884Z",
     "shell.execute_reply": "2026-01-10T08:39:27.037131Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.013728,
     "end_time": "2026-01-10T08:39:27.039009",
     "exception": false,
     "start_time": "2026-01-10T08:39:27.025281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DenseNetExtractor(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.features = models.densenet201(pretrained=pretrained).features\n",
    "    def forward(self, x):\n",
    "        feats = []\n",
    "        for name, layer in self.features._modules.items():\n",
    "            x = layer(x)\n",
    "            if name in [\"denseblock1\",\"denseblock2\",\"denseblock3\",\"denseblock4\"]:\n",
    "                feats.append(x)\n",
    "        return feats\n",
    "\n",
    "\n",
    "class MobileNetExtractor(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.features = models.mobilenet_v3_large(pretrained=pretrained).features\n",
    "    def forward(self, x):\n",
    "        feats = []\n",
    "        out = x\n",
    "        for i, layer in enumerate(self.features):\n",
    "            out = layer(out)\n",
    "            if i in (2,5,9,12):\n",
    "                feats.append(out)\n",
    "        if len(feats) < 4:\n",
    "            feats.append(out)\n",
    "        return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c5bf2f4",
   "metadata": {
    "_cell_guid": "602ab64f-0bcd-48fd-9c92-789c331c1ced",
    "_uuid": "4b565d5e-4ecb-457c-af1a-b89084719789",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-10T08:39:27.052028Z",
     "iopub.status.busy": "2026-01-10T08:39:27.051841Z",
     "iopub.status.idle": "2026-01-10T08:39:27.055526Z",
     "shell.execute_reply": "2026-01-10T08:39:27.054977Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.011397,
     "end_time": "2026-01-10T08:39:27.056517",
     "exception": false,
     "start_time": "2026-01-10T08:39:27.045120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SwinExtractor(nn.Module):\n",
    "    def __init__(self, model_name=\"swin_tiny_patch4_window7_224\", pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained, features_only=True)\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74d7526d",
   "metadata": {
    "_cell_guid": "595c7ef4-f65e-4c97-818d-db3dea350d48",
    "_uuid": "77d2613c-fd8c-4bc9-a03a-3fbfa9258379",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-10T08:39:27.069721Z",
     "iopub.status.busy": "2026-01-10T08:39:27.069542Z",
     "iopub.status.idle": "2026-01-10T08:39:27.074017Z",
     "shell.execute_reply": "2026-01-10T08:39:27.073537Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.012286,
     "end_time": "2026-01-10T08:39:27.074942",
     "exception": false,
     "start_time": "2026-01-10T08:39:27.062656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CBAMlite(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super().__init__()\n",
    "        self.se = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(channels, max(channels//reduction,4), 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(max(channels//reduction,4), channels, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.spatial = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels, 3, padding=1, groups=channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(channels, 1, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return x * self.se(x) * self.spatial(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91141977",
   "metadata": {
    "_cell_guid": "3691f4eb-fe5e-4a90-8355-281bfb975eee",
    "_uuid": "a7ab254f-2a14-444a-bd57-e45aa8620035",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-10T08:39:27.087927Z",
     "iopub.status.busy": "2026-01-10T08:39:27.087747Z",
     "iopub.status.idle": "2026-01-10T08:39:27.092440Z",
     "shell.execute_reply": "2026-01-10T08:39:27.091904Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.012276,
     "end_time": "2026-01-10T08:39:27.093407",
     "exception": false,
     "start_time": "2026-01-10T08:39:27.081131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GatedFusion(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.g_fc = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(dim, max(dim//4, 4), 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(max(dim//4,4), dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, H, X):\n",
    "        if H.shape[2:] != X.shape[2:]:\n",
    "            X = F.interpolate(X, size=H.shape[2:], mode='bilinear', align_corners=False)\n",
    "        g = self.g_fc(H)\n",
    "        return g * H + (1 - g) * X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2f293b6",
   "metadata": {
    "_cell_guid": "8e151f36-8629-46d4-8978-9dc6f44a874d",
    "_uuid": "95e9bd01-a25d-40bd-95d3-0d52401e3fd5",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-10T08:39:27.106297Z",
     "iopub.status.busy": "2026-01-10T08:39:27.106123Z",
     "iopub.status.idle": "2026-01-10T08:39:27.111686Z",
     "shell.execute_reply": "2026-01-10T08:39:27.111132Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.013252,
     "end_time": "2026-01-10T08:39:27.112764",
     "exception": false,
     "start_time": "2026-01-10T08:39:27.099512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CrossAttention(nn.Module):\n",
    "    def __init__(self, d_cnn, d_swin, d_out):\n",
    "        super().__init__()\n",
    "        self.q = nn.Linear(d_cnn, d_out)\n",
    "        self.k = nn.Linear(d_swin, d_out)\n",
    "        self.v = nn.Linear(d_swin, d_out)\n",
    "        self.scale = d_out ** -0.5\n",
    "    def forward(self, feat_cnn, feat_swin):\n",
    "        B, Cc, H, W = feat_cnn.shape\n",
    "        q = feat_cnn.permute(0,2,3,1).reshape(B, H*W, Cc)\n",
    "        if feat_swin.dim() == 4:\n",
    "            Bs, Cs, Hs, Ws = feat_swin.shape\n",
    "            kv = feat_swin.permute(0,2,3,1).reshape(Bs, Hs*Ws, Cs)\n",
    "        else:\n",
    "            kv = feat_swin\n",
    "        K = self.k(kv)\n",
    "        V = self.v(kv)\n",
    "        Q = self.q(q)\n",
    "        attn = torch.matmul(Q, K.transpose(-2, -1)) * self.scale\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        out = torch.matmul(attn, V)\n",
    "        out = out.reshape(B, H, W, -1).permute(0,3,1,2)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7319ea",
   "metadata": {
    "_cell_guid": "8d1a2d8c-d55a-4a1c-8242-9619a3169e93",
    "_uuid": "fdfd48ad-a120-426f-812d-eab414adf245",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.006005,
     "end_time": "2026-01-10T08:39:27.124829",
     "exception": false,
     "start_time": "2026-01-10T08:39:27.118824",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Segmentation Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51a0f208",
   "metadata": {
    "_cell_guid": "5ea62e96-bc4e-4218-a0ba-7009414c6204",
    "_uuid": "59784957-96f9-43f9-ab4c-ba4c5069c266",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-10T08:39:27.138172Z",
     "iopub.status.busy": "2026-01-10T08:39:27.137997Z",
     "iopub.status.idle": "2026-01-10T08:39:27.143322Z",
     "shell.execute_reply": "2026-01-10T08:39:27.142753Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.013136,
     "end_time": "2026-01-10T08:39:27.144379",
     "exception": false,
     "start_time": "2026-01-10T08:39:27.131243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SegDecoder(nn.Module):\n",
    "    def __init__(self, in_channels_list, mid_channels=128):\n",
    "        super().__init__()\n",
    "        self.projs = nn.ModuleList([nn.Conv2d(c, mid_channels, 1) for c in in_channels_list])\n",
    "        self.conv = nn.Sequential(nn.Conv2d(mid_channels * len(in_channels_list), mid_channels, 3, padding=1), nn.ReLU(inplace=True))\n",
    "        self.out = nn.Conv2d(mid_channels, 1, 1)\n",
    "    def forward(self, feat_list):\n",
    "        target_size = feat_list[0].shape[2:]\n",
    "        ups = []\n",
    "        for f, p in zip(feat_list, self.projs):\n",
    "            x = p(f)\n",
    "            if x.shape[2:] != target_size:\n",
    "                x = F.interpolate(x, size=target_size, mode='bilinear', align_corners=False)\n",
    "            ups.append(x)\n",
    "        x = torch.cat(ups, dim=1)\n",
    "        x = self.conv(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd8ad02",
   "metadata": {
    "_cell_guid": "226cd599-783c-4f41-8d35-ebcf350381b9",
    "_uuid": "f9354086-efdb-49de-9956-72bdc5c1c804",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.006026,
     "end_time": "2026-01-10T08:39:27.156514",
     "exception": false,
     "start_time": "2026-01-10T08:39:27.150488",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Probing Backbones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f9aab72",
   "metadata": {
    "_cell_guid": "2a3f1c47-b68b-4563-becc-b0d6171967fa",
    "_uuid": "c92e84d5-b62f-4c5c-baff-5897fd5bc9fe",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-10T08:39:27.169271Z",
     "iopub.status.busy": "2026-01-10T08:39:27.169074Z",
     "iopub.status.idle": "2026-01-10T08:39:33.769315Z",
     "shell.execute_reply": "2026-01-10T08:39:33.768459Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 6.608063,
     "end_time": "2026-01-10T08:39:33.770604",
     "exception": false,
     "start_time": "2026-01-10T08:39:27.162541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet201_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet201_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/densenet201-c1103571.pth\" to /root/.cache/torch/hub/checkpoints/densenet201-c1103571.pth\n",
      "100%|██████████| 77.4M/77.4M [00:00<00:00, 181MB/s]\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_large-8738ca79.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_large-8738ca79.pth\n",
      "100%|██████████| 21.1M/21.1M [00:00<00:00, 131MB/s] \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeb291dba05341d39121df8ad91bbb65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/114M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseNet channels: [256, 512, 1792, 1920]\n",
      "MobileNet channels: [24, 40, 80, 112]\n",
      "Swin channels: [56, 28, 14, 7]\n"
     ]
    }
   ],
   "source": [
    "dnet = DenseNetExtractor().to(device).eval()\n",
    "mnet = MobileNetExtractor().to(device).eval()\n",
    "snet = SwinExtractor().to(device).eval()\n",
    "with torch.no_grad():\n",
    "    dummy = torch.randn(1,3,IMG_SIZE,IMG_SIZE).to(device)\n",
    "    featsA = dnet(dummy)\n",
    "    featsB = mnet(dummy)\n",
    "    featsS = snet(dummy)\n",
    "chA = [f.shape[1] for f in featsA]\n",
    "chB = [f.shape[1] for f in featsB]\n",
    "chS = [f.shape[1] for f in featsS]\n",
    "print(\"DenseNet channels:\", chA)\n",
    "print(\"MobileNet channels:\", chB)\n",
    "print(\"Swin channels:\", chS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b38a439",
   "metadata": {
    "_cell_guid": "93c9df34-5655-4f06-8252-ebbc742d4db7",
    "_uuid": "42955826-da73-49eb-a2b6-1eb868ac3be0",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.006752,
     "end_time": "2026-01-10T08:39:33.784846",
     "exception": false,
     "start_time": "2026-01-10T08:39:33.778094",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Fusion Model (DenseNet + MobileNet + Swin cross attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39135627",
   "metadata": {
    "_cell_guid": "e1370fdf-9622-4230-b0ee-8c6cfe884584",
    "_uuid": "71df8e36-6644-423d-86c1-0b9cc366e4b4",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-10T08:39:33.799942Z",
     "iopub.status.busy": "2026-01-10T08:39:33.799221Z",
     "iopub.status.idle": "2026-01-10T08:39:34.998609Z",
     "shell.execute_reply": "2026-01-10T08:39:34.997790Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.208087,
     "end_time": "2026-01-10T08:39:34.999745",
     "exception": false,
     "start_time": "2026-01-10T08:39:33.791658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters (M): 51.586615\n"
     ]
    }
   ],
   "source": [
    "class FusionWithSwin(nn.Module):\n",
    "    def __init__(self, dense_chs, mobile_chs, swin_chs, d=256, use_seg=True, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.backA = DenseNetExtractor()\n",
    "        self.backB = MobileNetExtractor()\n",
    "        self.backS = SwinExtractor()\n",
    "        L = min(len(dense_chs), len(mobile_chs), len(swin_chs))\n",
    "        self.L = L\n",
    "        self.d = d\n",
    "        self.alignA = nn.ModuleList([nn.Conv2d(c, d, 1) for c in dense_chs[:L]])\n",
    "        self.alignB = nn.ModuleList([nn.Conv2d(c, d, 1) for c in mobile_chs[:L]])\n",
    "        self.cbamA = nn.ModuleList([CBAMlite(d) for _ in range(L)])\n",
    "        self.cbamB = nn.ModuleList([CBAMlite(d) for _ in range(L)])\n",
    "        self.gates = nn.ModuleList([GatedFusion(d) for _ in range(L)])\n",
    "        self.cross_atts = nn.ModuleList([CrossAttention(d, swin_chs[i], d) for i in range(L)])\n",
    "        self.reduce = nn.Conv2d(d * L, d, 1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(d, 512), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(512, 128), nn.ReLU(), nn.Dropout(0.5),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        self.use_seg = use_seg\n",
    "        if self.use_seg:\n",
    "            self.segdecoder = SegDecoder([d] * L, mid_channels=128)\n",
    "\n",
    "        # Domain head for DANN (simple MLP)\n",
    "        self.domain_head = nn.Sequential(\n",
    "            nn.Linear(d, 256), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(256, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, grl_lambda=0.0):\n",
    "        fa = self.backA(x)\n",
    "        fb = self.backB(x)\n",
    "        fs = self.backS(x)\n",
    "        fused_feats = []\n",
    "        aligned_for_dec = []\n",
    "        for i in range(self.L):\n",
    "            a = self.alignA[i](fa[i])\n",
    "            a = self.cbamA[i](a)\n",
    "            b = self.alignB[i](fb[i])\n",
    "            b = self.cbamB[i](b)\n",
    "            if b.shape[2:] != a.shape[2:]:\n",
    "                b = F.interpolate(b, size=a.shape[2:], mode='bilinear', align_corners=False)\n",
    "            fused = self.gates[i](a, b)\n",
    "            swin_feat = fs[i]\n",
    "            swin_att = self.cross_atts[i](fused, swin_feat)\n",
    "            if swin_att.shape[2:] != fused.shape[2:]:\n",
    "                swin_att = F.interpolate(swin_att, size=fused.shape[2:], mode='bilinear', align_corners=False)\n",
    "            fused = fused + swin_att\n",
    "            fused_feats.append(fused)\n",
    "            aligned_for_dec.append(fused)\n",
    "        target = fused_feats[-1]\n",
    "        upsampled = [F.interpolate(f, size=target.shape[2:], mode='bilinear', align_corners=False) if f.shape[2:] != target.shape[2:] else f for f in fused_feats]\n",
    "        concat = torch.cat(upsampled, dim=1)\n",
    "        fused = self.reduce(concat)\n",
    "        z = F.adaptive_avg_pool2d(fused, (1,1)).view(fused.size(0), -1)\n",
    "        logits = self.classifier(z)\n",
    "        out = {\"logits\": logits, \"feat\": z}\n",
    "        if self.use_seg:\n",
    "            out[\"seg\"] = self.segdecoder(aligned_for_dec)\n",
    "\n",
    "        # Domain prediction with GRL effect applied by multiplying lambda and reversing sign in custom grad fn\n",
    "        if grl_lambda > 0.0:\n",
    "            # GRL implemented outside (we'll pass z through GRL function)\n",
    "            pass\n",
    "        out[\"domain_logits\"] = self.domain_head(z)\n",
    "        return out\n",
    "\n",
    "# instantiate model\n",
    "model = FusionWithSwin(dense_chs=chA, mobile_chs=chB, swin_chs=chS, d=256, use_seg=USE_SEGMENTATION, num_classes=2).to(device)\n",
    "print(\"Model parameters (M):\", sum(p.numel() for p in model.parameters())/1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f445f277",
   "metadata": {
    "_cell_guid": "8981b77b-e686-4024-a7ef-106fc71c5573",
    "_uuid": "66ed0d4e-2188-4630-b4b8-da16939ceaf1",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-10T08:39:35.057812Z",
     "iopub.status.busy": "2026-01-10T08:39:35.057303Z",
     "iopub.status.idle": "2026-01-10T08:39:35.067126Z",
     "shell.execute_reply": "2026-01-10T08:39:35.066374Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.018864,
     "end_time": "2026-01-10T08:39:35.068167",
     "exception": false,
     "start_time": "2026-01-10T08:39:35.049303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LabelSmoothingCE(nn.Module):\n",
    "    def __init__(self, smoothing=0.1):\n",
    "        super().__init__()\n",
    "        self.s = smoothing\n",
    "    def forward(self, logits, target):\n",
    "        c = logits.size(-1)\n",
    "        logp = F.log_softmax(logits, dim=-1)\n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(logp)\n",
    "            true_dist.fill_(self.s / (c - 1))\n",
    "            true_dist.scatter_(1, target.unsqueeze(1), 1.0 - self.s)\n",
    "        return (-true_dist * logp).sum(dim=-1).mean()\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=1.5):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "    def forward(self, logits, target):\n",
    "        prob = F.softmax(logits, dim=1)\n",
    "        pt = prob.gather(1, target.unsqueeze(1)).squeeze(1)\n",
    "        ce = F.cross_entropy(logits, target, reduction='none')\n",
    "        loss = ((1 - pt) ** self.gamma) * ce\n",
    "        return loss.mean()\n",
    "\n",
    "def dice_loss_logits(pred_logits, target):\n",
    "    pred = torch.sigmoid(pred_logits)\n",
    "    target = target.float()\n",
    "    inter = (pred * target).sum(dim=(1,2,3))\n",
    "    denom = pred.sum(dim=(1,2,3)) + target.sum(dim=(1,2,3))\n",
    "    dice = (2 * inter + 1e-6) / (denom + 1e-6)\n",
    "    return 1.0 - dice.mean()\n",
    "\n",
    "clf_loss_ce = LabelSmoothingCE(LABEL_SMOOTH)\n",
    "clf_loss_focal = FocalLoss(gamma=1.5)\n",
    "seg_bce = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def dice_loss(pred, target, smooth=1.0):\n",
    "    pred = torch.sigmoid(pred)\n",
    "    num = 2 * (pred * target).sum() + smooth\n",
    "    den = pred.sum() + target.sum() + smooth\n",
    "    return 1 - (num / den)\n",
    "\n",
    "def seg_loss_fn(pred, mask):\n",
    "    if pred.shape[-2:] != mask.shape[-2:]:\n",
    "        pred = F.interpolate(pred, size=mask.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "    return F.binary_cross_entropy_with_logits(pred, mask) + dice_loss(pred, mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b1377f9",
   "metadata": {
    "_cell_guid": "6ab89b5b-ccc8-4af3-9590-bc566204b65a",
    "_uuid": "27aad2d9-4477-4430-b87c-2805045736df",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-10T08:39:35.082906Z",
     "iopub.status.busy": "2026-01-10T08:39:35.082689Z",
     "iopub.status.idle": "2026-01-10T08:39:35.088996Z",
     "shell.execute_reply": "2026-01-10T08:39:35.088298Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.014851,
     "end_time": "2026-01-10T08:39:35.090069",
     "exception": false,
     "start_time": "2026-01-10T08:39:35.075218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Supervised contrastive Loss\n",
    "class SupConLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.07):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.cos = nn.CosineSimilarity(dim=-1)\n",
    "    def forward(self, features, labels):\n",
    "        # features: [N, D], labels: [N]\n",
    "        device = features.device\n",
    "        f = F.normalize(features, dim=1)\n",
    "        sim = torch.matmul(f, f.T) / self.temperature  # [N,N]\n",
    "        labels = labels.contiguous().view(-1,1)\n",
    "        mask = torch.eq(labels, labels.T).float().to(device)\n",
    "        # remove diagonal\n",
    "        logits_max, _ = torch.max(sim, dim=1, keepdim=True)\n",
    "        logits = sim - logits_max.detach()\n",
    "        exp_logits = torch.exp(logits) * (1 - torch.eye(len(features), device=device))\n",
    "        denom = exp_logits.sum(1, keepdim=True)\n",
    "        # for each i, positive samples are where mask==1 (excluding self)\n",
    "        pos_mask = mask - torch.eye(len(features), device=device)\n",
    "        pos_exp = (exp_logits * pos_mask).sum(1)\n",
    "        # avoid divide by zero\n",
    "        loss = -torch.log((pos_exp + 1e-8) / (denom + 1e-8) + 1e-12)\n",
    "        # average only across anchors that have positives\n",
    "        valid = (pos_mask.sum(1) > 0).float()\n",
    "        loss = (loss * valid).sum() / (valid.sum() + 1e-8)\n",
    "        return loss\n",
    "supcon_loss_fn = SupConLoss(temperature=0.07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93d07e3c",
   "metadata": {
    "_cell_guid": "937a9a70-b252-4638-91b4-0acbcd8214f9",
    "_uuid": "ffb8ae99-636a-43c6-9797-f85ea97f4b17",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-10T08:39:35.104621Z",
     "iopub.status.busy": "2026-01-10T08:39:35.104388Z",
     "iopub.status.idle": "2026-01-10T08:39:35.108507Z",
     "shell.execute_reply": "2026-01-10T08:39:35.107832Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.01249,
     "end_time": "2026-01-10T08:39:35.109524",
     "exception": false,
     "start_time": "2026-01-10T08:39:35.097034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Domain Adversarial: Gradient Reversal Layer (GRL)\n",
    "\n",
    "from torch.autograd import Function\n",
    "class GradReverse(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, l):\n",
    "        ctx.l = l\n",
    "        return x.view_as(x)\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return grad_output.neg() * ctx.l, None\n",
    "\n",
    "def grad_reverse(x, l=1.0):\n",
    "    return GradReverse.apply(x, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8aba79e4",
   "metadata": {
    "_cell_guid": "5d0a6d0b-5ee0-459f-a9c4-f361ce6591ba",
    "_uuid": "73e24310-551f-4554-bb03-48f305bb7ae3",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-10T08:39:35.124740Z",
     "iopub.status.busy": "2026-01-10T08:39:35.124561Z",
     "iopub.status.idle": "2026-01-10T08:39:35.139318Z",
     "shell.execute_reply": "2026-01-10T08:39:35.138476Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.024006,
     "end_time": "2026-01-10T08:39:35.140393",
     "exception": false,
     "start_time": "2026-01-10T08:39:35.116387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20/4242938264.py:29: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(device==\"cuda\"))\n"
     ]
    }
   ],
   "source": [
    "# Optimizer + scheduler + mixed precision + clipping\n",
    "# -----------------------------\n",
    "# param groups: smaller LR for backbones, larger for heads\n",
    "backbone_params = []\n",
    "head_params = []\n",
    "for name, param in model.named_parameters():\n",
    "    if any(k in name for k in ['backA', 'backB', 'backS']):  # backbone names\n",
    "        backbone_params.append(param)\n",
    "    else:\n",
    "        head_params.append(param)\n",
    "\n",
    "opt = torch.optim.AdamW([\n",
    "    {'params': backbone_params, 'lr': LR * 0.2},\n",
    "    {'params': head_params, 'lr': LR}\n",
    "], lr=LR, weight_decay=1e-4)\n",
    "\n",
    "# warmup + cosine schedule\n",
    "def get_cosine_with_warmup_scheduler(optimizer, warmup_epochs, total_epochs, last_epoch=-1):\n",
    "    def lr_lambda(epoch):\n",
    "        if epoch < warmup_epochs:\n",
    "            return float(epoch) / float(max(1.0, warmup_epochs))\n",
    "        # cosine from warmup -> total\n",
    "        t = (epoch - warmup_epochs) / float(max(1, total_epochs - warmup_epochs))\n",
    "        return 0.5 * (1.0 + math.cos(math.pi * t))\n",
    "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda, last_epoch=last_epoch)\n",
    "\n",
    "scheduler = get_cosine_with_warmup_scheduler(opt, WARMUP_EPOCHS, EPOCHS)\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(device==\"cuda\"))\n",
    "\n",
    "# -----------------------------\n",
    "# Mixup & CutMix helpers\n",
    "# -----------------------------\n",
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(W * cut_rat)   # use builtin int\n",
    "    cut_h = int(H * cut_rat)   # use builtin int\n",
    "\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "def apply_mixup(x, y, alpha=MIXUP_ALPHA):\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    idx = torch.randperm(x.size(0))\n",
    "    mixed_x = lam * x + (1 - lam) * x[idx]\n",
    "    y_a, y_b = y, y[idx]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def apply_cutmix(x, y, alpha=CUTMIX_ALPHA):\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    idx = torch.randperm(x.size(0))\n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam)\n",
    "    new_x = x.clone()\n",
    "    new_x[:, :, bby1:bby2, bbx1:bbx2] = x[idx, :, bby1:bby2, bbx1:bbx2]\n",
    "    lam_adjusted = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (x.size(-1) * x.size(-2)))\n",
    "    return new_x, y, y[idx], lam_adjusted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ff5b3d",
   "metadata": {
    "_cell_guid": "8cefc78d-dfc4-4a80-853c-de8cdbaa0092",
    "_uuid": "98de1d78-23d6-4f6e-8856-1c2bf4801903",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.006826,
     "end_time": "2026-01-10T08:39:35.154133",
     "exception": false,
     "start_time": "2026-01-10T08:39:35.147307",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6fcebf00",
   "metadata": {
    "_cell_guid": "4e9e207b-133f-40e0-8941-e99fb09ea18c",
    "_uuid": "8f0812c9-bc6d-452f-b8dd-b4983872595a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2026-01-10T08:39:35.168820Z",
     "iopub.status.busy": "2026-01-10T08:39:35.168643Z",
     "iopub.status.idle": "2026-01-10T11:02:08.294527Z",
     "shell.execute_reply": "2026-01-10T11:02:08.293673Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 8553.778989,
     "end_time": "2026-01-10T11:02:08.939905",
     "exception": false,
     "start_time": "2026-01-10T08:39:35.160916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 1/15:   0%|          | 0/1076 [00:00<?, ?it/s]/tmp/ipykernel_20/1808691167.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
      "Train 1/15: 100%|██████████| 1076/1076 [06:02<00:00,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Loss: 4.1427 Acc: 0.4958 Prec: 0.4956 Rec: 0.4959 F1: 0.4873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Val Loss: 1.5630 Acc: 0.5850 Prec: 0.5098 Rec: 0.5046 F1: 0.4602\n",
      "Saved best model at epoch 1 (F1 0.4602)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 2/15:   0%|          | 0/1076 [00:00<?, ?it/s]/tmp/ipykernel_20/1808691167.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
      "Train 2/15: 100%|██████████| 1076/1076 [06:02<00:00,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Train Loss: 2.6646 Acc: 0.7035 Prec: 0.7092 Rec: 0.7028 F1: 0.7010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Val Loss: 2.0406 Acc: 0.8676 Prec: 0.8672 Rec: 0.8852 F1: 0.8659\n",
      "Saved best model at epoch 2 (F1 0.8659)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 3/15:   0%|          | 0/1076 [00:00<?, ?it/s]/tmp/ipykernel_20/1808691167.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
      "Train 3/15: 100%|██████████| 1076/1076 [06:02<00:00,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] Train Loss: 2.2931 Acc: 0.8021 Prec: 0.8022 Rec: 0.8021 F1: 0.8021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] Val Loss: 1.7109 Acc: 0.8164 Prec: 0.8366 Rec: 0.8470 F1: 0.8161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 4/15:   0%|          | 0/1076 [00:00<?, ?it/s]/tmp/ipykernel_20/1808691167.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
      "Train 4/15: 100%|██████████| 1076/1076 [06:03<00:00,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] Train Loss: 2.2104 Acc: 0.7985 Prec: 0.7986 Rec: 0.7985 F1: 0.7985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] Val Loss: 0.9468 Acc: 0.9642 Prec: 0.9592 Rec: 0.9674 F1: 0.9628\n",
      "Saved best model at epoch 4 (F1 0.9628)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 5/15:   0%|          | 0/1076 [00:00<?, ?it/s]/tmp/ipykernel_20/1808691167.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
      "Train 5/15: 100%|██████████| 1076/1076 [06:02<00:00,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] Train Loss: 2.2205 Acc: 0.8058 Prec: 0.8059 Rec: 0.8057 F1: 0.8058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] Val Loss: 0.9819 Acc: 0.9312 Prec: 0.9253 Rec: 0.9433 F1: 0.9297\n",
      "--- Unfreezing all backbone layers at epoch 6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 6/15:   0%|          | 0/1076 [00:00<?, ?it/s]/tmp/ipykernel_20/1808691167.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
      "Train 6/15: 100%|██████████| 1076/1076 [09:55<00:00,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] Train Loss: 1.9184 Acc: 0.8492 Prec: 0.8492 Rec: 0.8492 F1: 0.8492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] Val Loss: 0.9150 Acc: 0.9954 Prec: 0.9943 Rec: 0.9960 F1: 0.9951\n",
      "Saved best model at epoch 6 (F1 0.9951)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 7/15:   0%|          | 0/1076 [00:00<?, ?it/s]/tmp/ipykernel_20/1808691167.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
      "Train 7/15: 100%|██████████| 1076/1076 [09:52<00:00,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] Train Loss: 1.7610 Acc: 0.8747 Prec: 0.8747 Rec: 0.8747 F1: 0.8747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] Val Loss: 0.9027 Acc: 0.9912 Prec: 0.9890 Rec: 0.9927 F1: 0.9908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 8/15:   0%|          | 0/1076 [00:00<?, ?it/s]/tmp/ipykernel_20/1808691167.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
      "Train 8/15: 100%|██████████| 1076/1076 [09:52<00:00,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] Train Loss: 1.7072 Acc: 0.8890 Prec: 0.8891 Rec: 0.8890 F1: 0.8890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] Val Loss: 0.9077 Acc: 0.9851 Prec: 0.9817 Rec: 0.9878 F1: 0.9845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 9/15:   0%|          | 0/1076 [00:00<?, ?it/s]/tmp/ipykernel_20/1808691167.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
      "Train 9/15: 100%|██████████| 1076/1076 [09:52<00:00,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] Train Loss: 1.6449 Acc: 0.8781 Prec: 0.8782 Rec: 0.8781 F1: 0.8781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] Val Loss: 0.9004 Acc: 0.9837 Prec: 0.9801 Rec: 0.9866 F1: 0.9831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 10/15:   0%|          | 0/1076 [00:00<?, ?it/s]/tmp/ipykernel_20/1808691167.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
      "Train 10/15: 100%|██████████| 1076/1076 [09:52<00:00,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] Train Loss: 1.6613 Acc: 0.8698 Prec: 0.8699 Rec: 0.8698 F1: 0.8698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] Val Loss: 0.8884 Acc: 0.9893 Prec: 0.9867 Rec: 0.9912 F1: 0.9888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 11/15:   0%|          | 0/1076 [00:00<?, ?it/s]/tmp/ipykernel_20/1808691167.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
      "Train 11/15: 100%|██████████| 1076/1076 [09:52<00:00,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11] Train Loss: 1.6576 Acc: 0.8700 Prec: 0.8700 Rec: 0.8700 F1: 0.8700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11] Val Loss: 0.8789 Acc: 0.9958 Prec: 0.9947 Rec: 0.9966 F1: 0.9956\n",
      "Saved best model at epoch 11 (F1 0.9956)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 12/15:   0%|          | 0/1076 [00:00<?, ?it/s]/tmp/ipykernel_20/1808691167.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
      "Train 12/15: 100%|██████████| 1076/1076 [09:51<00:00,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12] Train Loss: 1.4904 Acc: 0.8765 Prec: 0.8765 Rec: 0.8766 F1: 0.8765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12] Val Loss: 0.8797 Acc: 0.9949 Prec: 0.9936 Rec: 0.9958 F1: 0.9946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 13/15:   0%|          | 0/1076 [00:00<?, ?it/s]/tmp/ipykernel_20/1808691167.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
      "Train 13/15: 100%|██████████| 1076/1076 [09:51<00:00,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13] Train Loss: 1.5433 Acc: 0.8776 Prec: 0.8778 Rec: 0.8776 F1: 0.8776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13] Val Loss: 0.8790 Acc: 0.9940 Prec: 0.9924 Rec: 0.9950 F1: 0.9937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 14/15:   0%|          | 0/1076 [00:00<?, ?it/s]/tmp/ipykernel_20/1808691167.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
      "Train 14/15: 100%|██████████| 1076/1076 [09:52<00:00,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14] Train Loss: 1.4855 Acc: 0.8852 Prec: 0.8854 Rec: 0.8853 F1: 0.8852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14] Val Loss: 0.8789 Acc: 0.9921 Prec: 0.9901 Rec: 0.9935 F1: 0.9917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 15/15:   0%|          | 0/1076 [00:00<?, ?it/s]/tmp/ipykernel_20/1808691167.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
      "Train 15/15: 100%|██████████| 1076/1076 [09:52<00:00,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15] Train Loss: 1.4553 Acc: 0.8698 Prec: 0.8702 Rec: 0.8696 F1: 0.8698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15] Val Loss: 0.8778 Acc: 0.9940 Prec: 0.9924 Rec: 0.9950 F1: 0.9937\n",
      "Training finished. Best val F1: 0.9956203339698864 at epoch 11\n"
     ]
    }
   ],
   "source": [
    "best_vf1 = 0.0\n",
    "best_epoch = 0\n",
    "patience_count = 0\n",
    "\n",
    "def compute_combined_clf_loss(logits, targets, mix_info=None, use_focal=False):\n",
    "    # mix_info: (mode, y_a, y_b, lam) or None\n",
    "    if mix_info is None:\n",
    "        if use_focal:\n",
    "            return clf_loss_focal(logits, targets)\n",
    "        else:\n",
    "            return clf_loss_ce(logits, targets)\n",
    "    else:\n",
    "        # mixup/cutmix: soft labels\n",
    "        y_a, y_b, lam = mix_info\n",
    "        if use_focal:\n",
    "            # focal is not designed for soft labels; approximate by weighted CE\n",
    "            loss = lam * F.cross_entropy(logits, y_a) + (1 - lam) * F.cross_entropy(logits, y_b)\n",
    "        else:\n",
    "            loss = lam * clf_loss_ce(logits, y_a) + (1 - lam) * clf_loss_ce(logits, y_b)\n",
    "        return loss\n",
    "\n",
    "history = {\n",
    "    'train_loss': [], 'train_f1': [], 'train_acc': [],\n",
    "    'val_loss': [], 'val_f1': [], 'val_acc': []\n",
    "}\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    # --- CHANGED: Improved freeze/unfreeze strategy ---\n",
    "    # We set FREEZE_EPOCHS = 5 in cell 5 (to match WARMUP_EPOCHS)\n",
    "    if epoch <= FREEZE_EPOCHS:\n",
    "        # Freeze ALL backbone parameters\n",
    "        for name, p in model.named_parameters():\n",
    "            if any(k in name for k in ['backA', 'backB', 'backS']):\n",
    "                p.requires_grad = False\n",
    "    elif epoch == FREEZE_EPOCHS + 1:\n",
    "        # Unfreeze all parameters *once* after freeze period\n",
    "        print(f\"--- Unfreezing all backbone layers at epoch {epoch} ---\")\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    y_true, y_pred = [], []\n",
    "    n_batches = 0\n",
    "\n",
    "    opt.zero_grad() \n",
    "    \n",
    "    for i, (weak_imgs, strong_imgs, labels, masks) in enumerate(tqdm(train_loader, desc=f\"Train {epoch}/{EPOCHS}\")):\n",
    "        weak_imgs = weak_imgs.to(device); strong_imgs = strong_imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        if masks is not None:\n",
    "            masks = masks.to(device)\n",
    "\n",
    "        # combine weak and strong optionally for the classifier path; we'll feed weak to model for main forward\n",
    "        imgs = weak_imgs\n",
    "\n",
    "        # optionally apply mixup/cutmix on imgs (on weak view)\n",
    "        mix_info = None\n",
    "        rand = random.random()\n",
    "        if rand < PROB_MIXUP:\n",
    "            imgs, y_a, y_b, lam = apply_mixup(imgs, labels)\n",
    "            mix_info = (y_a.to(device), y_b.to(device), lam)\n",
    "        elif rand < PROB_MIXUP + PROB_CUTMIX:\n",
    "            imgs, y_a, y_b, lam = apply_cutmix(imgs, labels)\n",
    "            mix_info = (y_a.to(device), y_b.to(device), lam)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
    "            out = model(imgs)  # returns logits, feat, seg, domain_logits\n",
    "            logits = out[\"logits\"]\n",
    "            feat = out[\"feat\"]\n",
    "            seg_out = out.get(\"seg\", None)\n",
    "            domain_logits = out.get(\"domain_logits\", None)\n",
    "\n",
    "            # classification loss (label-smoothing or focal)\n",
    "            clf_loss = compute_combined_clf_loss(logits, labels, mix_info=mix_info, use_focal=False)\n",
    "\n",
    "            # segmentation loss if available & mask present\n",
    "            seg_loss = 0.0\n",
    "            if USE_SEGMENTATION and (masks is not None):\n",
    "                seg_pred = out[\"seg\"]\n",
    "                seg_loss = seg_loss_fn(seg_pred, masks)\n",
    "            # supcon loss on features (use features from weak)\n",
    "            supcon_loss = supcon_loss_fn(feat, labels)\n",
    "\n",
    "            # consistency: forward strong view and compare predictions\n",
    "            out_strong = model(strong_imgs)\n",
    "            logits_strong = out_strong[\"logits\"]\n",
    "            probs_weak = F.softmax(logits.detach(), dim=1)\n",
    "            probs_strong = F.softmax(logits_strong, dim=1)\n",
    "            # L2 between probability vectors (could be KL)\n",
    "            cons_loss = F.mse_loss(probs_weak, probs_strong)\n",
    "            # domain adversarial: need domain labels; for now assume source-only (skip) unless domain label available\n",
    "            dom_loss = 0.0\n",
    "\n",
    "            total_loss = clf_loss + GAMMA_SEG * seg_loss + BETA_SUPCON * supcon_loss + ETA_CONS * cons_loss + ALPHA_DOM * dom_loss\n",
    "\n",
    "            # 2. Scale the loss by accumulation steps to average the gradients\n",
    "            total_loss = total_loss / ACCUMULATION_STEPS \n",
    "\n",
    "        # Perform backward pass (gradients are accumulated until step is called)\n",
    "        scaler.scale(total_loss).backward()\n",
    "\n",
    "        # 3. Optimizer step only every ACCUMULATION_STEPS batches\n",
    "        if (i + 1) % ACCUMULATION_STEPS == 0:\n",
    "            # gradient clipping before step\n",
    "            scaler.unscale_(opt)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            scaler.step(opt)\n",
    "            scaler.update()\n",
    "            opt.zero_grad() # Prepare for next accumulation cycle\n",
    "\n",
    "        running_loss += total_loss.item() * ACCUMULATION_STEPS # Re-scale back for correct loss tracking\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(logits.argmax(1).cpu().numpy())\n",
    "        n_batches += 1\n",
    "\n",
    "    # 4. Take a final step if there are remaining gradients (i.e., last batch was not a multiple of ACCUMULATION_STEPS)\n",
    "    if n_batches % ACCUMULATION_STEPS != 0:\n",
    "        scaler.unscale_(opt)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        scaler.step(opt)\n",
    "        scaler.update()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # metrics (rest of the code remains the same)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "    print(f\"[Epoch {epoch}] Train Loss: {running_loss/max(1,n_batches):.4f} Acc: {acc:.4f} Prec: {prec:.4f} Rec: {rec:.4f} F1: {f1:.4f}\")\n",
    "\n",
    "    # -------------------\n",
    "    # VALIDATION\n",
    "    # -------------------\n",
    "    model.eval()\n",
    "    val_y_true, val_y_pred = [], []\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for weak_imgs, _, labels, masks in val_loader:\n",
    "            imgs = weak_imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            if masks is not None:\n",
    "                masks = masks.to(device)\n",
    "\n",
    "            out = model(imgs)\n",
    "            logits = out[\"logits\"]\n",
    "            feat = out[\"feat\"]\n",
    "            seg_out = out.get(\"seg\", None)\n",
    "            loss = compute_combined_clf_loss(logits, labels, mix_info=None, use_focal=False)\n",
    "            if USE_SEGMENTATION and (masks is not None):\n",
    "                # loss += seg_loss_fn(seg_out, masks)\n",
    "                loss += GAMMA_SEG * seg_loss_fn(seg_out, masks)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            val_y_true.extend(labels.cpu().numpy())\n",
    "            val_y_pred.extend(logits.argmax(1).cpu().numpy())\n",
    "\n",
    "    vacc = accuracy_score(val_y_true, val_y_pred)\n",
    "    vprec, vrec, vf1, _ = precision_recall_fscore_support(val_y_true, val_y_pred, average=\"macro\", zero_division=0)\n",
    "    print(f\"[Epoch {epoch}] Val Loss: {val_loss/max(1,len(val_loader)):.4f} Acc: {vacc:.4f} Prec: {vprec:.4f} Rec: {vrec:.4f} F1: {vf1:.4f}\")\n",
    "\n",
    "\n",
    "    history['train_loss'].append(running_loss / max(1, n_batches))\n",
    "    history['train_f1'].append(f1)\n",
    "    history['train_acc'].append(acc)\n",
    "    history['val_loss'].append(val_loss / max(1, len(val_loader)))\n",
    "    history['val_f1'].append(vf1)\n",
    "    history['val_acc'].append(vacc)\n",
    "\n",
    "    # early stopping & save best\n",
    "    if vf1 > best_vf1:\n",
    "        best_vf1 = vf1\n",
    "        best_epoch = epoch\n",
    "        torch.save({\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state\": model.state_dict(),\n",
    "            \"opt_state\": opt.state_dict(),\n",
    "            \"best_vf1\": best_vf1\n",
    "        }, SAVE_PATH)\n",
    "        patience_count = 0\n",
    "        print(f\"Saved best model at epoch {epoch} (F1 {best_vf1:.4f})\")\n",
    "    else:\n",
    "        patience_count += 1\n",
    "        if patience_count >= EARLY_STOPPING_PATIENCE:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "print(\"Training finished. Best val F1:\", best_vf1, \"at epoch\", best_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f9eaa3",
   "metadata": {
    "papermill": {
     "duration": 0.631932,
     "end_time": "2026-01-10T11:02:10.264125",
     "exception": false,
     "start_time": "2026-01-10T11:02:09.632193",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "2nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "283367b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T11:02:11.596544Z",
     "iopub.status.busy": "2026-01-10T11:02:11.596206Z",
     "iopub.status.idle": "2026-01-10T11:03:09.371377Z",
     "shell.execute_reply": "2026-01-10T11:03:09.370699Z"
    },
    "papermill": {
     "duration": 59.099802,
     "end_time": "2026-01-10T11:03:10.067337",
     "exception": false,
     "start_time": "2026-01-10T11:02:10.967535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 12604 samples from 4 root directories.\n",
      "✅ Loaded 4000 samples from 4 root directories.\n",
      "Total Train samples: 12604 Total Val samples: 4000\n"
     ]
    }
   ],
   "source": [
    "info_dir = \"/kaggle/input/cod10k/COD10K-v3/Info\"\n",
    "train_dir_cod = \"/kaggle/input/cod10k/COD10K-v3/Train\" \n",
    "test_dir_cod = \"/kaggle/input/cod10k/COD10K-v3/Test\"  \n",
    "    \n",
    "# COD10K Info files\n",
    "train_cam_txt = os.path.join(info_dir, \"CAM_train.txt\")\n",
    "train_noncam_txt = os.path.join(info_dir, \"NonCAM_train.txt\")\n",
    "test_cam_txt = os.path.join(info_dir, \"CAM_test.txt\")\n",
    "test_noncam_txt = os.path.join(info_dir, \"NonCAM_test.txt\")\n",
    "\n",
    "# CAMO-COCO PATHS\n",
    "info_dir2 = \"/kaggle/input/camo-coco/CAMO_COCO/Info\"\n",
    "\n",
    "# CAMO-COCO Info files\n",
    "train_cam_txt2 = os.path.join(info_dir2, \"camo_train.txt\")\n",
    "train_noncam_txt2 = os.path.join(info_dir2, \"non_camo_train.txt\")\n",
    "test_cam_txt2 = os.path.join(info_dir2, \"camo_test.txt\")\n",
    "test_noncam_txt2 = os.path.join(info_dir2, \"non_camo_test.txt\")\n",
    "\n",
    "# CAMO-COCO Root Directories\n",
    "train_dir_camo_cam = \"/kaggle/input/camo-coco/CAMO_COCO/Camouflage\"\n",
    "train_dir_camo_noncam = \"/kaggle/input/camo-coco/CAMO_COCO/Non_Camouflage\"\n",
    "\n",
    "# third dataset - NC4K + non-camouflage (places 365)\n",
    "testing_info_file = \"/kaggle/input/testing-dataset/Info/image_labels.txt\"\n",
    "testing_images_dir = \"/kaggle/input/testing-dataset/Images\"\n",
    "testing_image_paths, testing_labels = load_testing_dataset_info(testing_info_file, testing_images_dir)\n",
    "# 1. Load the testing dataset info\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "    testing_image_paths, testing_labels, test_size=0.2, random_state=42\n",
    ")\n",
    "# 1. All Root Directories\n",
    "ALL_ROOT_DIRS = [\n",
    "    train_dir_cod,       \n",
    "    test_dir_cod,       \n",
    "    train_dir_camo_cam,  \n",
    "    train_dir_camo_noncam\n",
    "]\n",
    "# 2. Training TXT files: ALL COD10K/CAMO-COCO data (both train and test splits)\n",
    "ALL_TRAIN_TXTS = [\n",
    "    train_cam_txt, train_noncam_txt, \n",
    "]\n",
    "# 3. Validation TXT files: ONLY the 80% testing-dataset split will be used, so this list is empty.\n",
    "ALL_VAL_TXTS = [test_cam_txt, test_noncam_txt]\n",
    "train_ds = MultiDataset(\n",
    "    root_dirs=ALL_ROOT_DIRS, \n",
    "    txt_files=ALL_TRAIN_TXTS,               \n",
    "    testing_image_paths=train_paths,        \n",
    "    testing_labels=train_labels,            \n",
    "    weak_transform=weak_tf, \n",
    "    strong_transform=strong_tf, \n",
    "    use_masks=USE_SEGMENTATION\n",
    ")   # Validation Dataset: No external data (via empty ALL_VAL_TXTS) + 80% testing-dataset split (via val_paths)\n",
    "val_ds = MultiDataset(\n",
    "    root_dirs=ALL_ROOT_DIRS,  \n",
    "    txt_files=ALL_VAL_TXTS,                 \n",
    "    testing_image_paths=None,              \n",
    "    testing_labels=None,              \n",
    "    weak_transform=val_tf, \n",
    "    strong_transform=None, \n",
    "    use_masks=USE_SEGMENTATION\n",
    ")\n",
    "\n",
    "# Build Sampler and DataLoader\n",
    "train_sampler = build_weighted_sampler(train_ds)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, sampler=train_sampler, num_workers=NUM_WORKERS)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "print(\"Total Train samples:\", len(train_ds), \"Total Val samples:\", len(val_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5fa08797",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T11:03:11.383177Z",
     "iopub.status.busy": "2026-01-10T11:03:11.382400Z",
     "iopub.status.idle": "2026-01-10T11:03:12.669547Z",
     "shell.execute_reply": "2026-01-10T11:03:12.668722Z"
    },
    "papermill": {
     "duration": 1.978876,
     "end_time": "2026-01-10T11:03:12.670800",
     "exception": false,
     "start_time": "2026-01-10T11:03:10.691924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet201_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet201_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseNet channels: [256, 512, 1792, 1920]\n",
      "MobileNet channels: [24, 40, 80, 112]\n",
      "Swin channels: [56, 28, 14, 7]\n"
     ]
    }
   ],
   "source": [
    "dnet = DenseNetExtractor().to(device).eval()\n",
    "mnet = MobileNetExtractor().to(device).eval()\n",
    "snet = SwinExtractor().to(device).eval()\n",
    "with torch.no_grad():\n",
    "    dummy = torch.randn(1,3,IMG_SIZE,IMG_SIZE).to(device)\n",
    "    featsA = dnet(dummy)\n",
    "    featsB = mnet(dummy)\n",
    "    featsS = snet(dummy)\n",
    "chA = [f.shape[1] for f in featsA]\n",
    "chB = [f.shape[1] for f in featsB]\n",
    "chS = [f.shape[1] for f in featsS]\n",
    "print(\"DenseNet channels:\", chA)\n",
    "print(\"MobileNet channels:\", chB)\n",
    "print(\"Swin channels:\", chS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee492818",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T11:03:14.032738Z",
     "iopub.status.busy": "2026-01-10T11:03:14.032479Z",
     "iopub.status.idle": "2026-01-10T11:03:15.200059Z",
     "shell.execute_reply": "2026-01-10T11:03:15.199329Z"
    },
    "papermill": {
     "duration": 1.888024,
     "end_time": "2026-01-10T11:03:15.201349",
     "exception": false,
     "start_time": "2026-01-10T11:03:13.313325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters (M): 51.586615\n"
     ]
    }
   ],
   "source": [
    "class FusionWithSwin(nn.Module):\n",
    "    def __init__(self, dense_chs, mobile_chs, swin_chs, d=256, use_seg=True, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.backA = DenseNetExtractor()\n",
    "        self.backB = MobileNetExtractor()\n",
    "        self.backS = SwinExtractor()\n",
    "        L = min(len(dense_chs), len(mobile_chs), len(swin_chs))\n",
    "        self.L = L\n",
    "        self.d = d\n",
    "        self.alignA = nn.ModuleList([nn.Conv2d(c, d, 1) for c in dense_chs[:L]])\n",
    "        self.alignB = nn.ModuleList([nn.Conv2d(c, d, 1) for c in mobile_chs[:L]])\n",
    "        self.cbamA = nn.ModuleList([CBAMlite(d) for _ in range(L)])\n",
    "        self.cbamB = nn.ModuleList([CBAMlite(d) for _ in range(L)])\n",
    "        self.gates = nn.ModuleList([GatedFusion(d) for _ in range(L)])\n",
    "        self.cross_atts = nn.ModuleList([CrossAttention(d, swin_chs[i], d) for i in range(L)])\n",
    "        self.reduce = nn.Conv2d(d * L, d, 1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(d, 512), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(512, 128), nn.ReLU(), nn.Dropout(0.5),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        self.use_seg = use_seg\n",
    "        if self.use_seg:\n",
    "            self.segdecoder = SegDecoder([d] * L, mid_channels=128)\n",
    "\n",
    "        # Domain head for DANN (simple MLP)\n",
    "        self.domain_head = nn.Sequential(\n",
    "            nn.Linear(d, 256), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(256, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, grl_lambda=0.0):\n",
    "        fa = self.backA(x)\n",
    "        fb = self.backB(x)\n",
    "        fs = self.backS(x)\n",
    "        fused_feats = []\n",
    "        aligned_for_dec = []\n",
    "        for i in range(self.L):\n",
    "            a = self.alignA[i](fa[i])\n",
    "            a = self.cbamA[i](a)\n",
    "            b = self.alignB[i](fb[i])\n",
    "            b = self.cbamB[i](b)\n",
    "            if b.shape[2:] != a.shape[2:]:\n",
    "                b = F.interpolate(b, size=a.shape[2:], mode='bilinear', align_corners=False)\n",
    "            fused = self.gates[i](a, b)\n",
    "            swin_feat = fs[i]\n",
    "            swin_att = self.cross_atts[i](fused, swin_feat)\n",
    "            if swin_att.shape[2:] != fused.shape[2:]:\n",
    "                swin_att = F.interpolate(swin_att, size=fused.shape[2:], mode='bilinear', align_corners=False)\n",
    "            fused = fused + swin_att\n",
    "            fused_feats.append(fused)\n",
    "            aligned_for_dec.append(fused)\n",
    "        target = fused_feats[-1]\n",
    "        upsampled = [F.interpolate(f, size=target.shape[2:], mode='bilinear', align_corners=False) if f.shape[2:] != target.shape[2:] else f for f in fused_feats]\n",
    "        concat = torch.cat(upsampled, dim=1)\n",
    "        fused = self.reduce(concat)\n",
    "        z = F.adaptive_avg_pool2d(fused, (1,1)).view(fused.size(0), -1)\n",
    "        logits = self.classifier(z)\n",
    "        out = {\"logits\": logits, \"feat\": z}\n",
    "        if self.use_seg:\n",
    "            out[\"seg\"] = self.segdecoder(aligned_for_dec)\n",
    "\n",
    "        # Domain prediction with GRL effect applied by multiplying lambda and reversing sign in custom grad fn\n",
    "        if grl_lambda > 0.0:\n",
    "            # GRL implemented outside (we'll pass z through GRL function)\n",
    "            pass\n",
    "        out[\"domain_logits\"] = self.domain_head(z)\n",
    "        return out\n",
    "\n",
    "# instantiate model\n",
    "model = FusionWithSwin(dense_chs=chA, mobile_chs=chB, swin_chs=chS, d=256, use_seg=USE_SEGMENTATION, num_classes=2).to(device)\n",
    "print(\"Model parameters (M):\", sum(p.numel() for p in model.parameters())/1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5aa8c59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T11:03:16.523498Z",
     "iopub.status.busy": "2026-01-10T11:03:16.523219Z",
     "iopub.status.idle": "2026-01-10T11:03:16.532805Z",
     "shell.execute_reply": "2026-01-10T11:03:16.532260Z"
    },
    "papermill": {
     "duration": 0.636081,
     "end_time": "2026-01-10T11:03:16.533869",
     "exception": false,
     "start_time": "2026-01-10T11:03:15.897788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LabelSmoothingCE(nn.Module):\n",
    "    def __init__(self, smoothing=0.1):\n",
    "        super().__init__()\n",
    "        self.s = smoothing\n",
    "    def forward(self, logits, target):\n",
    "        c = logits.size(-1)\n",
    "        logp = F.log_softmax(logits, dim=-1)\n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(logp)\n",
    "            true_dist.fill_(self.s / (c - 1))\n",
    "            true_dist.scatter_(1, target.unsqueeze(1), 1.0 - self.s)\n",
    "        return (-true_dist * logp).sum(dim=-1).mean()\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=1.5):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "    def forward(self, logits, target):\n",
    "        prob = F.softmax(logits, dim=1)\n",
    "        pt = prob.gather(1, target.unsqueeze(1)).squeeze(1)\n",
    "        ce = F.cross_entropy(logits, target, reduction='none')\n",
    "        loss = ((1 - pt) ** self.gamma) * ce\n",
    "        return loss.mean()\n",
    "\n",
    "def dice_loss_logits(pred_logits, target):\n",
    "    pred = torch.sigmoid(pred_logits)\n",
    "    target = target.float()\n",
    "    inter = (pred * target).sum(dim=(1,2,3))\n",
    "    denom = pred.sum(dim=(1,2,3)) + target.sum(dim=(1,2,3))\n",
    "    dice = (2 * inter + 1e-6) / (denom + 1e-6)\n",
    "    return 1.0 - dice.mean()\n",
    "\n",
    "clf_loss_ce = LabelSmoothingCE(LABEL_SMOOTH)\n",
    "clf_loss_focal = FocalLoss(gamma=1.5)\n",
    "seg_bce = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def dice_loss(pred, target, smooth=1.0):\n",
    "    pred = torch.sigmoid(pred)\n",
    "    num = 2 * (pred * target).sum() + smooth\n",
    "    den = pred.sum() + target.sum() + smooth\n",
    "    return 1 - (num / den)\n",
    "\n",
    "def seg_loss_fn(pred, mask):\n",
    "    if pred.shape[-2:] != mask.shape[-2:]:\n",
    "        pred = F.interpolate(pred, size=mask.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "    return F.binary_cross_entropy_with_logits(pred, mask) + dice_loss(pred, mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18e65ae8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T11:03:17.856561Z",
     "iopub.status.busy": "2026-01-10T11:03:17.856279Z",
     "iopub.status.idle": "2026-01-10T11:03:17.863253Z",
     "shell.execute_reply": "2026-01-10T11:03:17.862543Z"
    },
    "papermill": {
     "duration": 0.708247,
     "end_time": "2026-01-10T11:03:17.864507",
     "exception": false,
     "start_time": "2026-01-10T11:03:17.156260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Supervised contrastive Loss\n",
    "class SupConLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.07):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.cos = nn.CosineSimilarity(dim=-1)\n",
    "    def forward(self, features, labels):\n",
    "        # features: [N, D], labels: [N]\n",
    "        device = features.device\n",
    "        f = F.normalize(features, dim=1)\n",
    "        sim = torch.matmul(f, f.T) / self.temperature  # [N,N]\n",
    "        labels = labels.contiguous().view(-1,1)\n",
    "        mask = torch.eq(labels, labels.T).float().to(device)\n",
    "        # remove diagonal\n",
    "        logits_max, _ = torch.max(sim, dim=1, keepdim=True)\n",
    "        logits = sim - logits_max.detach()\n",
    "        exp_logits = torch.exp(logits) * (1 - torch.eye(len(features), device=device))\n",
    "        denom = exp_logits.sum(1, keepdim=True)\n",
    "        # for each i, positive samples are where mask==1 (excluding self)\n",
    "        pos_mask = mask - torch.eye(len(features), device=device)\n",
    "        pos_exp = (exp_logits * pos_mask).sum(1)\n",
    "        # avoid divide by zero\n",
    "        loss = -torch.log((pos_exp + 1e-8) / (denom + 1e-8) + 1e-12)\n",
    "        # average only across anchors that have positives\n",
    "        valid = (pos_mask.sum(1) > 0).float()\n",
    "        loss = (loss * valid).sum() / (valid.sum() + 1e-8)\n",
    "        return loss\n",
    "supcon_loss_fn = SupConLoss(temperature=0.07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3069aa2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T11:03:19.183115Z",
     "iopub.status.busy": "2026-01-10T11:03:19.182859Z",
     "iopub.status.idle": "2026-01-10T11:03:19.187455Z",
     "shell.execute_reply": "2026-01-10T11:03:19.186880Z"
    },
    "papermill": {
     "duration": 0.7018,
     "end_time": "2026-01-10T11:03:19.188673",
     "exception": false,
     "start_time": "2026-01-10T11:03:18.486873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Domain Adversarial: Gradient Reversal Layer (GRL)\n",
    "\n",
    "from torch.autograd import Function\n",
    "class GradReverse(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, l):\n",
    "        ctx.l = l\n",
    "        return x.view_as(x)\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return grad_output.neg() * ctx.l, None\n",
    "\n",
    "def grad_reverse(x, l=1.0):\n",
    "    return GradReverse.apply(x, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64e30ba6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T11:03:20.500570Z",
     "iopub.status.busy": "2026-01-10T11:03:20.500280Z",
     "iopub.status.idle": "2026-01-10T11:03:20.525151Z",
     "shell.execute_reply": "2026-01-10T11:03:20.524361Z"
    },
    "papermill": {
     "duration": 0.71572,
     "end_time": "2026-01-10T11:03:20.526326",
     "exception": false,
     "start_time": "2026-01-10T11:03:19.810606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20/4242938264.py:29: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(device==\"cuda\"))\n"
     ]
    }
   ],
   "source": [
    "# Optimizer + scheduler + mixed precision + clipping\n",
    "# -----------------------------\n",
    "# param groups: smaller LR for backbones, larger for heads\n",
    "backbone_params = []\n",
    "head_params = []\n",
    "for name, param in model.named_parameters():\n",
    "    if any(k in name for k in ['backA', 'backB', 'backS']):  # backbone names\n",
    "        backbone_params.append(param)\n",
    "    else:\n",
    "        head_params.append(param)\n",
    "\n",
    "opt = torch.optim.AdamW([\n",
    "    {'params': backbone_params, 'lr': LR * 0.2},\n",
    "    {'params': head_params, 'lr': LR}\n",
    "], lr=LR, weight_decay=1e-4)\n",
    "\n",
    "# warmup + cosine schedule\n",
    "def get_cosine_with_warmup_scheduler(optimizer, warmup_epochs, total_epochs, last_epoch=-1):\n",
    "    def lr_lambda(epoch):\n",
    "        if epoch < warmup_epochs:\n",
    "            return float(epoch) / float(max(1.0, warmup_epochs))\n",
    "        # cosine from warmup -> total\n",
    "        t = (epoch - warmup_epochs) / float(max(1, total_epochs - warmup_epochs))\n",
    "        return 0.5 * (1.0 + math.cos(math.pi * t))\n",
    "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda, last_epoch=last_epoch)\n",
    "\n",
    "scheduler = get_cosine_with_warmup_scheduler(opt, WARMUP_EPOCHS, EPOCHS)\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(device==\"cuda\"))\n",
    "\n",
    "# -----------------------------\n",
    "# Mixup & CutMix helpers\n",
    "# -----------------------------\n",
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(W * cut_rat)   # use builtin int\n",
    "    cut_h = int(H * cut_rat)   # use builtin int\n",
    "\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "def apply_mixup(x, y, alpha=MIXUP_ALPHA):\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    idx = torch.randperm(x.size(0))\n",
    "    mixed_x = lam * x + (1 - lam) * x[idx]\n",
    "    y_a, y_b = y, y[idx]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def apply_cutmix(x, y, alpha=CUTMIX_ALPHA):\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    idx = torch.randperm(x.size(0))\n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam)\n",
    "    new_x = x.clone()\n",
    "    new_x[:, :, bby1:bby2, bbx1:bbx2] = x[idx, :, bby1:bby2, bbx1:bbx2]\n",
    "    lam_adjusted = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (x.size(-1) * x.size(-2)))\n",
    "    return new_x, y, y[idx], lam_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e00262e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-10T11:03:21.848077Z",
     "iopub.status.busy": "2026-01-10T11:03:21.847753Z",
     "iopub.status.idle": "2026-01-10T14:39:22.751648Z",
     "shell.execute_reply": "2026-01-10T14:39:22.750489Z"
    },
    "papermill": {
     "duration": 12961.978127,
     "end_time": "2026-01-10T14:39:23.135683",
     "exception": false,
     "start_time": "2026-01-10T11:03:21.157556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 1/15:   0%|          | 0/1576 [00:00<?, ?it/s]/tmp/ipykernel_20/1808691167.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
      "Train 1/15: 100%|██████████| 1576/1576 [08:55<00:00,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Loss: 6.0379 Acc: 0.4832 Prec: 0.4808 Rec: 0.4864 F1: 0.4441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Val Loss: 1.5912 Acc: 0.4168 Prec: 0.4144 Rec: 0.4159 F1: 0.4137\n",
      "Saved best model at epoch 1 (F1 0.4137)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 2/15:   0%|          | 0/1576 [00:00<?, ?it/s]/tmp/ipykernel_20/1808691167.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
      "Train 2/15: 100%|██████████| 1576/1576 [08:55<00:00,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Train Loss: 2.9848 Acc: 0.6458 Prec: 0.6497 Rec: 0.6467 F1: 0.6443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Val Loss: 1.6373 Acc: 0.7782 Prec: 0.7826 Rec: 0.7791 F1: 0.7777\n",
      "Saved best model at epoch 2 (F1 0.7777)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 3/15:   0%|          | 0/1576 [00:00<?, ?it/s]/tmp/ipykernel_20/1808691167.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
      "Train 3/15: 100%|██████████| 1576/1576 [08:56<00:00,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] Train Loss: 2.6627 Acc: 0.7383 Prec: 0.7386 Rec: 0.7384 F1: 0.7383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] Val Loss: 1.7011 Acc: 0.7987 Prec: 0.8100 Rec: 0.8000 F1: 0.7973\n",
      "Saved best model at epoch 3 (F1 0.7973)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 4/15:   0%|          | 0/1576 [00:00<?, ?it/s]/tmp/ipykernel_20/1808691167.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
      "Train 4/15: 100%|██████████| 1576/1576 [08:57<00:00,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] Train Loss: 2.6637 Acc: 0.7320 Prec: 0.7324 Rec: 0.7320 F1: 0.7319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] Val Loss: 1.0805 Acc: 0.8357 Prec: 0.8367 Rec: 0.8354 F1: 0.8355\n",
      "Saved best model at epoch 4 (F1 0.8355)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 5/15:   0%|          | 0/1576 [00:00<?, ?it/s]/tmp/ipykernel_20/1808691167.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
      "Train 5/15: 100%|██████████| 1576/1576 [08:56<00:00,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] Train Loss: 2.6065 Acc: 0.7333 Prec: 0.7334 Rec: 0.7331 F1: 0.7331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] Val Loss: 1.0626 Acc: 0.8495 Prec: 0.8509 Rec: 0.8491 F1: 0.8492\n",
      "Saved best model at epoch 5 (F1 0.8492)\n",
      "--- Unfreezing all backbone layers at epoch 6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 6/15:   0%|          | 0/1576 [00:00<?, ?it/s]/tmp/ipykernel_20/1808691167.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
      "Train 6/15: 100%|██████████| 1576/1576 [14:37<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] Train Loss: 2.3908 Acc: 0.7786 Prec: 0.7790 Rec: 0.7788 F1: 0.7785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] Val Loss: 1.0512 Acc: 0.8580 Prec: 0.8717 Rec: 0.8567 F1: 0.8563\n",
      "Saved best model at epoch 6 (F1 0.8563)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 7/15:   0%|          | 0/1576 [00:00<?, ?it/s]/tmp/ipykernel_20/1808691167.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
      "Train 7/15: 100%|██████████| 1576/1576 [14:34<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] Train Loss: 2.1626 Acc: 0.8183 Prec: 0.8186 Rec: 0.8181 F1: 0.8182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] Val Loss: 0.9970 Acc: 0.8600 Prec: 0.8804 Rec: 0.8584 F1: 0.8577\n",
      "Saved best model at epoch 7 (F1 0.8577)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 8/15:   0%|          | 0/1576 [00:00<?, ?it/s]/tmp/ipykernel_20/1808691167.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
      "Train 8/15: 100%|██████████| 1576/1576 [14:35<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] Train Loss: 2.0962 Acc: 0.8316 Prec: 0.8316 Rec: 0.8314 F1: 0.8315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] Val Loss: 0.9658 Acc: 0.8880 Prec: 0.8916 Rec: 0.8874 F1: 0.8876\n",
      "Saved best model at epoch 8 (F1 0.8876)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 9/15:   0%|          | 0/1576 [00:00<?, ?it/s]/tmp/ipykernel_20/1808691167.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
      "Train 9/15: 100%|██████████| 1576/1576 [14:34<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] Train Loss: 2.0485 Acc: 0.8351 Prec: 0.8354 Rec: 0.8350 F1: 0.8350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] Val Loss: 0.9524 Acc: 0.8788 Prec: 0.8941 Rec: 0.8774 F1: 0.8773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 10/15:   0%|          | 0/1576 [00:00<?, ?it/s]/tmp/ipykernel_20/1808691167.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
      "Train 10/15: 100%|██████████| 1576/1576 [14:35<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] Train Loss: 1.9855 Acc: 0.8370 Prec: 0.8371 Rec: 0.8371 F1: 0.8370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] Val Loss: 0.9633 Acc: 0.8772 Prec: 0.8940 Rec: 0.8759 F1: 0.8756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 11/15:   0%|          | 0/1576 [00:00<?, ?it/s]/tmp/ipykernel_20/1808691167.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
      "Train 11/15: 100%|██████████| 1576/1576 [14:35<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11] Train Loss: 1.9156 Acc: 0.8454 Prec: 0.8455 Rec: 0.8454 F1: 0.8454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11] Val Loss: 0.9531 Acc: 0.8900 Prec: 0.9000 Rec: 0.8889 F1: 0.8891\n",
      "Saved best model at epoch 11 (F1 0.8891)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 12/15:   0%|          | 0/1576 [00:00<?, ?it/s]/tmp/ipykernel_20/1808691167.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
      "Train 12/15: 100%|██████████| 1576/1576 [14:36<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12] Train Loss: 1.8599 Acc: 0.8521 Prec: 0.8523 Rec: 0.8520 F1: 0.8520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12] Val Loss: 0.9596 Acc: 0.9062 Prec: 0.9123 Rec: 0.9054 F1: 0.9058\n",
      "Saved best model at epoch 12 (F1 0.9058)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 13/15:   0%|          | 0/1576 [00:00<?, ?it/s]/tmp/ipykernel_20/1808691167.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
      "Train 13/15: 100%|██████████| 1576/1576 [14:36<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13] Train Loss: 1.8498 Acc: 0.8438 Prec: 0.8438 Rec: 0.8439 F1: 0.8438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13] Val Loss: 0.9591 Acc: 0.8878 Prec: 0.9001 Rec: 0.8866 F1: 0.8866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 14/15:   0%|          | 0/1576 [00:00<?, ?it/s]/tmp/ipykernel_20/1808691167.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
      "Train 14/15: 100%|██████████| 1576/1576 [14:37<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14] Train Loss: 1.8043 Acc: 0.8492 Prec: 0.8492 Rec: 0.8493 F1: 0.8492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14] Val Loss: 0.9500 Acc: 0.9002 Prec: 0.9087 Rec: 0.8993 F1: 0.8996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 15/15:   0%|          | 0/1576 [00:00<?, ?it/s]/tmp/ipykernel_20/1808691167.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
      "Train 15/15: 100%|██████████| 1576/1576 [14:36<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15] Train Loss: 1.7368 Acc: 0.8558 Prec: 0.8558 Rec: 0.8558 F1: 0.8558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15] Val Loss: 0.9432 Acc: 0.9073 Prec: 0.9128 Rec: 0.9065 F1: 0.9068\n",
      "Saved best model at epoch 15 (F1 0.9068)\n",
      "Training finished. Best val F1: 0.9068095294163822 at epoch 15\n"
     ]
    }
   ],
   "source": [
    "best_vf1 = 0.0\n",
    "best_epoch = 0\n",
    "patience_count = 0\n",
    "\n",
    "def compute_combined_clf_loss(logits, targets, mix_info=None, use_focal=False):\n",
    "    # mix_info: (mode, y_a, y_b, lam) or None\n",
    "    if mix_info is None:\n",
    "        if use_focal:\n",
    "            return clf_loss_focal(logits, targets)\n",
    "        else:\n",
    "            return clf_loss_ce(logits, targets)\n",
    "    else:\n",
    "        # mixup/cutmix: soft labels\n",
    "        y_a, y_b, lam = mix_info\n",
    "        if use_focal:\n",
    "            # focal is not designed for soft labels; approximate by weighted CE\n",
    "            loss = lam * F.cross_entropy(logits, y_a) + (1 - lam) * F.cross_entropy(logits, y_b)\n",
    "        else:\n",
    "            loss = lam * clf_loss_ce(logits, y_a) + (1 - lam) * clf_loss_ce(logits, y_b)\n",
    "        return loss\n",
    "\n",
    "history = {\n",
    "    'train_loss': [], 'train_f1': [], 'train_acc': [],\n",
    "    'val_loss': [], 'val_f1': [], 'val_acc': []\n",
    "}\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    # --- CHANGED: Improved freeze/unfreeze strategy ---\n",
    "    # We set FREEZE_EPOCHS = 5 in cell 5 (to match WARMUP_EPOCHS)\n",
    "    if epoch <= FREEZE_EPOCHS:\n",
    "        # Freeze ALL backbone parameters\n",
    "        for name, p in model.named_parameters():\n",
    "            if any(k in name for k in ['backA', 'backB', 'backS']):\n",
    "                p.requires_grad = False\n",
    "    elif epoch == FREEZE_EPOCHS + 1:\n",
    "        # Unfreeze all parameters *once* after freeze period\n",
    "        print(f\"--- Unfreezing all backbone layers at epoch {epoch} ---\")\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    y_true, y_pred = [], []\n",
    "    n_batches = 0\n",
    "\n",
    "    opt.zero_grad() \n",
    "    \n",
    "    for i, (weak_imgs, strong_imgs, labels, masks) in enumerate(tqdm(train_loader, desc=f\"Train {epoch}/{EPOCHS}\")):\n",
    "        weak_imgs = weak_imgs.to(device); strong_imgs = strong_imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        if masks is not None:\n",
    "            masks = masks.to(device)\n",
    "\n",
    "        # combine weak and strong optionally for the classifier path; we'll feed weak to model for main forward\n",
    "        imgs = weak_imgs\n",
    "\n",
    "        # optionally apply mixup/cutmix on imgs (on weak view)\n",
    "        mix_info = None\n",
    "        rand = random.random()\n",
    "        if rand < PROB_MIXUP:\n",
    "            imgs, y_a, y_b, lam = apply_mixup(imgs, labels)\n",
    "            mix_info = (y_a.to(device), y_b.to(device), lam)\n",
    "        elif rand < PROB_MIXUP + PROB_CUTMIX:\n",
    "            imgs, y_a, y_b, lam = apply_cutmix(imgs, labels)\n",
    "            mix_info = (y_a.to(device), y_b.to(device), lam)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
    "            out = model(imgs)  # returns logits, feat, seg, domain_logits\n",
    "            logits = out[\"logits\"]\n",
    "            feat = out[\"feat\"]\n",
    "            seg_out = out.get(\"seg\", None)\n",
    "            domain_logits = out.get(\"domain_logits\", None)\n",
    "\n",
    "            # classification loss (label-smoothing or focal)\n",
    "            clf_loss = compute_combined_clf_loss(logits, labels, mix_info=mix_info, use_focal=False)\n",
    "\n",
    "            # segmentation loss if available & mask present\n",
    "            seg_loss = 0.0\n",
    "            if USE_SEGMENTATION and (masks is not None):\n",
    "                seg_pred = out[\"seg\"]\n",
    "                seg_loss = seg_loss_fn(seg_pred, masks)\n",
    "            # supcon loss on features (use features from weak)\n",
    "            supcon_loss = supcon_loss_fn(feat, labels)\n",
    "\n",
    "            # consistency: forward strong view and compare predictions\n",
    "            out_strong = model(strong_imgs)\n",
    "            logits_strong = out_strong[\"logits\"]\n",
    "            probs_weak = F.softmax(logits.detach(), dim=1)\n",
    "            probs_strong = F.softmax(logits_strong, dim=1)\n",
    "            # L2 between probability vectors (could be KL)\n",
    "            cons_loss = F.mse_loss(probs_weak, probs_strong)\n",
    "            # domain adversarial: need domain labels; for now assume source-only (skip) unless domain label available\n",
    "            dom_loss = 0.0\n",
    "\n",
    "            total_loss = clf_loss + GAMMA_SEG * seg_loss + BETA_SUPCON * supcon_loss + ETA_CONS * cons_loss + ALPHA_DOM * dom_loss\n",
    "\n",
    "            # 2. Scale the loss by accumulation steps to average the gradients\n",
    "            total_loss = total_loss / ACCUMULATION_STEPS \n",
    "\n",
    "        # Perform backward pass (gradients are accumulated until step is called)\n",
    "        scaler.scale(total_loss).backward()\n",
    "\n",
    "        # 3. Optimizer step only every ACCUMULATION_STEPS batches\n",
    "        if (i + 1) % ACCUMULATION_STEPS == 0:\n",
    "            # gradient clipping before step\n",
    "            scaler.unscale_(opt)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            scaler.step(opt)\n",
    "            scaler.update()\n",
    "            opt.zero_grad() # Prepare for next accumulation cycle\n",
    "\n",
    "        running_loss += total_loss.item() * ACCUMULATION_STEPS # Re-scale back for correct loss tracking\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(logits.argmax(1).cpu().numpy())\n",
    "        n_batches += 1\n",
    "\n",
    "    # 4. Take a final step if there are remaining gradients (i.e., last batch was not a multiple of ACCUMULATION_STEPS)\n",
    "    if n_batches % ACCUMULATION_STEPS != 0:\n",
    "        scaler.unscale_(opt)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        scaler.step(opt)\n",
    "        scaler.update()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # metrics (rest of the code remains the same)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "    print(f\"[Epoch {epoch}] Train Loss: {running_loss/max(1,n_batches):.4f} Acc: {acc:.4f} Prec: {prec:.4f} Rec: {rec:.4f} F1: {f1:.4f}\")\n",
    "\n",
    "    # -------------------\n",
    "    # VALIDATION\n",
    "    # -------------------\n",
    "    model.eval()\n",
    "    val_y_true, val_y_pred = [], []\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for weak_imgs, _, labels, masks in val_loader:\n",
    "            imgs = weak_imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            if masks is not None:\n",
    "                masks = masks.to(device)\n",
    "\n",
    "            out = model(imgs)\n",
    "            logits = out[\"logits\"]\n",
    "            feat = out[\"feat\"]\n",
    "            seg_out = out.get(\"seg\", None)\n",
    "            loss = compute_combined_clf_loss(logits, labels, mix_info=None, use_focal=False)\n",
    "            if USE_SEGMENTATION and (masks is not None):\n",
    "                # loss += seg_loss_fn(seg_out, masks)\n",
    "                loss += GAMMA_SEG * seg_loss_fn(seg_out, masks)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            val_y_true.extend(labels.cpu().numpy())\n",
    "            val_y_pred.extend(logits.argmax(1).cpu().numpy())\n",
    "\n",
    "    vacc = accuracy_score(val_y_true, val_y_pred)\n",
    "    vprec, vrec, vf1, _ = precision_recall_fscore_support(val_y_true, val_y_pred, average=\"macro\", zero_division=0)\n",
    "    print(f\"[Epoch {epoch}] Val Loss: {val_loss/max(1,len(val_loader)):.4f} Acc: {vacc:.4f} Prec: {vprec:.4f} Rec: {vrec:.4f} F1: {vf1:.4f}\")\n",
    "\n",
    "\n",
    "    history['train_loss'].append(running_loss / max(1, n_batches))\n",
    "    history['train_f1'].append(f1)\n",
    "    history['train_acc'].append(acc)\n",
    "    history['val_loss'].append(val_loss / max(1, len(val_loader)))\n",
    "    history['val_f1'].append(vf1)\n",
    "    history['val_acc'].append(vacc)\n",
    "\n",
    "    # early stopping & save best\n",
    "    if vf1 > best_vf1:\n",
    "        best_vf1 = vf1\n",
    "        best_epoch = epoch\n",
    "        torch.save({\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state\": model.state_dict(),\n",
    "            \"opt_state\": opt.state_dict(),\n",
    "            \"best_vf1\": best_vf1\n",
    "        }, SAVE_PATH)\n",
    "        patience_count = 0\n",
    "        print(f\"Saved best model at epoch {epoch} (F1 {best_vf1:.4f})\")\n",
    "    else:\n",
    "        patience_count += 1\n",
    "        if patience_count >= EARLY_STOPPING_PATIENCE:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "print(\"Training finished. Best val F1:\", best_vf1, \"at epoch\", best_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ae2f94",
   "metadata": {
    "papermill": {
     "duration": 1.56371,
     "end_time": "2026-01-10T14:39:26.410575",
     "exception": false,
     "start_time": "2026-01-10T14:39:24.846865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bd6fe9",
   "metadata": {
    "papermill": {
     "duration": 1.681571,
     "end_time": "2026-01-10T14:39:29.837656",
     "exception": false,
     "start_time": "2026-01-10T14:39:28.156085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2eea43",
   "metadata": {
    "papermill": {
     "duration": 1.674857,
     "end_time": "2026-01-10T14:39:33.164541",
     "exception": false,
     "start_time": "2026-01-10T14:39:31.489684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c584e2",
   "metadata": {
    "papermill": {
     "duration": 1.670227,
     "end_time": "2026-01-10T14:39:36.531101",
     "exception": false,
     "start_time": "2026-01-10T14:39:34.860874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 2932761,
     "sourceId": 5051281,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8580489,
     "sourceId": 13514489,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8582404,
     "sourceId": 13517101,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 21677.865503,
   "end_time": "2026-01-10T14:39:41.902396",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-10T08:38:24.036893",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0f51ff1bbaba456abff1517b1d729d11": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_96137d0022e44a968051e62884dac8d0",
       "placeholder": "​",
       "style": "IPY_MODEL_2562bff4d2e4400f98285e6615b68087",
       "tabbable": null,
       "tooltip": null,
       "value": " 114M/114M [00:02&lt;00:00, 98.4MB/s]"
      }
     },
     "242511228e304e56be52cce30c3c9459": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "24e7908a816e4ecf82786cf20a3227eb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_49dece6fc77c4558959d2344827fcc66",
       "placeholder": "​",
       "style": "IPY_MODEL_a845ccc4906a4ff1a0c5d96f31382414",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "2562bff4d2e4400f98285e6615b68087": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2eef686477da4f63a9a8e5de1daa381e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "49dece6fc77c4558959d2344827fcc66": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "96137d0022e44a968051e62884dac8d0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a845ccc4906a4ff1a0c5d96f31382414": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "aeb291dba05341d39121df8ad91bbb65": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_24e7908a816e4ecf82786cf20a3227eb",
        "IPY_MODEL_b5adf4fe43a74ea585c54b0c1a9bca8d",
        "IPY_MODEL_0f51ff1bbaba456abff1517b1d729d11"
       ],
       "layout": "IPY_MODEL_242511228e304e56be52cce30c3c9459",
       "tabbable": null,
       "tooltip": null
      }
     },
     "b5adf4fe43a74ea585c54b0c1a9bca8d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_de430af1d3a741d382364ac83b97928d",
       "max": 114286722.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2eef686477da4f63a9a8e5de1daa381e",
       "tabbable": null,
       "tooltip": null,
       "value": 114286722.0
      }
     },
     "de430af1d3a741d382364ac83b97928d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
